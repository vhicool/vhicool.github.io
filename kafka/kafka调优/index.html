<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>kafka性能调优 | 二九的博客</title><meta name="author" content="vhicool"><meta name="copyright" content="vhicool"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="操作系统调优 挂载（Mount）文件系统时禁掉 atime 更新 atime 的全称是 access time，记录的是文件最后被访问的时间。记录 atime 需要操作系统访问 inode 资源，而禁掉 atime 可以避免 inode 访问时间的写入操作，减少文件系统的写操作数。你可以执行 mount -o noatime 命令进行设置。  文件系统选择  至少选择ext4 或 XFS，尤其是">
<meta property="og:type" content="article">
<meta property="og:title" content="kafka性能调优">
<meta property="og:url" content="https://vhicool.github.io/kafka/kafka%E8%B0%83%E4%BC%98/index.html">
<meta property="og:site_name" content="二九的博客">
<meta property="og:description" content="操作系统调优 挂载（Mount）文件系统时禁掉 atime 更新 atime 的全称是 access time，记录的是文件最后被访问的时间。记录 atime 需要操作系统访问 inode 资源，而禁掉 atime 可以避免 inode 访问时间的写入操作，减少文件系统的写操作数。你可以执行 mount -o noatime 命令进行设置。  文件系统选择  至少选择ext4 或 XFS，尤其是">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://vhicool.github.io/img/erjiu.jpeg">
<meta property="article:published_time" content="2025-07-07T14:17:30.000Z">
<meta property="article:modified_time" content="2025-07-13T11:11:49.465Z">
<meta property="article:author" content="vhicool">
<meta property="article:tag" content="java">
<meta property="article:tag" content="kafka">
<meta property="article:tag" content="消息中间件">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://vhicool.github.io/img/erjiu.jpeg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "kafka性能调优",
  "url": "https://vhicool.github.io/kafka/kafka%E8%B0%83%E4%BC%98/",
  "image": "https://vhicool.github.io/img/erjiu.jpeg",
  "datePublished": "2025-07-07T14:17:30.000Z",
  "dateModified": "2025-07-13T11:11:49.465Z",
  "author": [
    {
      "@type": "Person",
      "name": "vhicool",
      "url": "https://vhicool.github.io/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://vhicool.github.io/kafka/kafka%E8%B0%83%E4%BC%98/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'kafka性能调优',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div class="post" id="body-wrap"><header class="post-bg fixed" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">二九的博客</span></a><a class="nav-page-title" href="/"><span class="site-name">kafka性能调优</span></a></span><div id="menus"></div></nav><div id="post-info"><h1 class="post-title">kafka性能调优</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-07-07T14:17:30.000Z" title="发表于 2025-07-07 22:17:30">2025-07-07</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-07-13T11:11:49.465Z" title="更新于 2025-07-13 19:11:49">2025-07-13</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/kafka/">kafka</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h2 id="操作系统调优"><a href="#操作系统调优" class="headerlink" title="操作系统调优"></a>操作系统调优</h2><ol>
<li><p>挂载（Mount）文件系统时禁掉 atime 更新</p>
<p>atime 的全称是 access time，记录的是文件最后被访问的时间。记录 atime 需要操作系统访问 inode 资源，而禁掉 atime 可以避免 inode 访问时间的写入操作，减少文件系统的写操作数。你可以执行 mount -o noatime 命令进行设置。</p>
</li>
<li><p>文件系统选择</p>
<ul>
<li><p>至少选择ext4 或 XFS，尤其是 XFS 文件系统，它具有高性能、高伸缩性等特点，特别适用于生产服务器。</p>
</li>
<li><p>ZFS 多级缓存的机制能够帮助 Kafka 改善 I&#x2F;O 性能</p>
</li>
</ul>
</li>
<li><p>swap 空间的设置</p>
<p>建议将swappiness 设置成一个很小的值，比如 1～10 之间，以防止 Linux 的 OOM Killer 开启随意杀掉进程</p>
<p>临时设置：sudo sysctl vm.swappiness&#x3D;N</p>
<p>永久设置：修改 &#x2F;etc&#x2F;sysctl.conf 文件，增加 vm.swappiness&#x3D;N，然后重启机器</p>
</li>
<li><p>ulimit -n</p>
<p>如果设置得太小，你会碰到 Too Many File Open 这类的错误。设置方法</p>
</li>
<li><p>vm.max_map_count</p>
<p>如果太小，在一个主题数超多的 Broker 机器上，你会碰到 OutOfMemoryError：Map failed 的严重错误。建议设置：655360。</p>
<p>设置方法：修改 &#x2F;etc&#x2F;sysctl.conf 文件，增加 vm.max_map_count&#x3D;655360，保存之后，执行 sysctl -p 命令使它生效</p>
</li>
<li><p>操作系统页缓存大小</p>
<p>给 Kafka 预留的页缓存越大越好，最小值至少要容纳一个日志段的大小，也就是 Broker 端参数 log.segment.bytes 的值。该参数的默认值是 1GB。预留出一个日志段大小，至少能保证 Kafka 可以将整个日志段全部放入页缓存，这样，消费者程序在消费时能直接命中页缓存，从而避免昂贵的物理磁盘 I&#x2F;O 操作</p>
</li>
</ol>
<h2 id="JVM-层调优"><a href="#JVM-层调优" class="headerlink" title="JVM 层调优"></a>JVM 层调优</h2><ol>
<li><p>设置堆大小</p>
<p>默认将 JVM 堆大小设置成 <strong>6～8GB</strong>。</p>
<p>设置标准：查询broker的GC log，Full GC 之后堆上存活对象的总大小，然后把堆大小设置为该值的 1.5～2 倍。可手动运行 jmap -histo:live &lt; pid &gt; 就能人为触发 Full GC</p>
</li>
<li><p>GC 收集器的选择</p>
<p><strong>G1 收集器</strong>，如果经常有Full GC，配置-XX:+PrintAdaptiveSizePolicy，查看到底是谁导致的 Full GC。</p>
<p>**大对象（Large Object）**优化，如果集群中消息体较大（比如超过1MB），一般是指至少占用半个区域（Region）大小的对象。举个例子，如果你的区域尺寸是 2MB，那么超过 1MB 大小的对象就被视为是大对象。要解决这个问题，除了增加堆大小之外，你还可以适当地增加区域大小，设置方法是增加 JVM 启动参数 -XX:+G1HeapRegionSize&#x3D;N。默认情况下，如果一个对象超过了 N&#x2F;2，就会被视为大对象，从而直接被分配在大对象区。</p>
</li>
</ol>
<h2 id="Broker-端调优"><a href="#Broker-端调优" class="headerlink" title="Broker 端调优"></a>Broker 端调优</h2><ol>
<li><p>即尽力保持客户端版本和 Broker 端版本一致</p>
<p>Producer -&gt; Broker -&gt; Consumer三端kafka版本要保持一致。版本不一致会令 Kafka 丧失很多性能收益，比如 Zero Copy。</p>
<p>Producer、Consumer 和 Broker 的版本是相同的，它们之间的通信可以享受 Zero Copy 的快速通道；相反，一个低版本的 Consumer 程序想要与 Producer、Broker 交互的话，就只能依靠 JVM 堆中转一下，丢掉了快捷通道，就只能走慢速通道了</p>
</li>
<li><p>配置调优</p>
</li>
</ol>
<h2 id="应用层调优"><a href="#应用层调优" class="headerlink" title="应用层调优"></a>应用层调优</h2><ol>
<li><p>不要频繁地创建 Producer 和 Consumer 对象实例</p>
</li>
<li><p>用完及时关闭</p>
<p>这些对象底层会创建很多物理资源，如 Socket 连接、ByteBuffer 缓冲区等。不及时关闭的话，势必造成资源泄露。</p>
</li>
<li><p>合理利用多线程来改善性能</p>
<p>Kafka 的 Java Producer 是线程安全的，你可以放心地在多个线程中共享同一个实例</p>
</li>
</ol>
<h2 id="性能指标调优"><a href="#性能指标调优" class="headerlink" title="性能指标调优"></a>性能指标调优</h2><h3 id="1-调优吞吐量"><a href="#1-调优吞吐量" class="headerlink" title="1. 调优吞吐量"></a>1. 调优吞吐量</h3><ul>
<li><p>broker端</p>
<ul>
<li><p>适当增加num.replica.fetchers参数值，但不超过CPU核数</p>
<p>表示的是 Follower 副本用多少个线程来拉取消息，默认使用 1 个线程。如果你的 Broker 端 CPU 资源很充足，不妨适当调大该参数值，加快 Follower 副本的同步速度。</p>
<p><strong>配置了 acks&#x3D;all 的 Producer 程序吞吐量被拖累的首要因素，就是副本同步性能</strong></p>
</li>
<li><p>调优GC参数，避免频繁的Full GC</p>
</li>
</ul>
</li>
<li><p>Producer</p>
<ul>
<li>适当增加batch.size的值，比如模式16K增加到512KB或1MB</li>
<li>适当增量linger.ms值，比如10-100</li>
<li>设置compression.type&#x3D;lz4或zstd</li>
<li>设置ack&#x3D;0或1（消息等级高的主题不建议）</li>
<li>设置retries&#x3D;0（消息等级高的主题不建议）</li>
<li>如果多线程共享Producer实例，增加buffer.memory的值</li>
</ul>
</li>
<li><p>Consumer</p>
<ul>
<li>采用多Consumer进程，或线程同时消费</li>
<li>增加fetch.min.bytes参数值，如大于1kb</li>
</ul>
</li>
</ul>
<h3 id="2-调优延时"><a href="#2-调优延时" class="headerlink" title="2. 调优延时"></a>2. 调优延时</h3><ul>
<li>broker端<ul>
<li>适当增加num.replica.fetchers参数值</li>
</ul>
</li>
<li>Producer<ul>
<li>减少设置linger.ms，比如为0</li>
<li>不启用消息压缩，compression.type&#x3D;none</li>
<li>设置ack&#x3D;1</li>
</ul>
</li>
<li>Consumer<ul>
<li>设置fetch.min.bytes&#x3D;1</li>
</ul>
</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://vhicool.github.io">vhicool</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://vhicool.github.io/kafka/kafka%E8%B0%83%E4%BC%98/">https://vhicool.github.io/kafka/kafka%E8%B0%83%E4%BC%98/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://vhicool.github.io" target="_blank">二九的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/java/">java</a><a class="post-meta__tags" href="/tags/kafka/">kafka</a><a class="post-meta__tags" href="/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/">消息中间件</a></div><div class="post-share"><div class="social-share" data-image="/img/erjiu.jpeg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/kafka/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/" title="Kafka常用命令，日常运维必备"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">Kafka常用命令，日常运维必备</div></div><div class="info-2"><div class="info-item-1">主题 创建主题  –zookeeper 会绕过 Kafka 的安全体系。这就是说，即使你为 Kafka 集群设置了安全认证，限制了主题的创建，如果你使用 –zookeeper 的命令，依然能成功创建任意主题，不受认证体系的约束  1bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 2 --topic test   直接使用–bootstrap-server 与集群进行交互  1bin/kafka-topics.sh --bootstrap-server broker_host:port --create --topic my_topic_name  --partitions 1 --replication-factor 1  发送消息 1bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test  查询指定topic 1bin/kafka-topics.sh...</div></div></div></a><a class="pagination-related" href="/kafka/%E4%BD%8D%E7%82%B9%E4%B8%BB%E9%A2%98-_consumer_offsets/" title="Kafka位点主题：_consumer_offsets是什么"><img class="cover" src="https://vhicool.github.io/kafka/%E4%BD%8D%E7%82%B9%E4%B8%BB%E9%A2%98-_consumer_offsets/86a44073aa60ac33e0833e6a9bfd9ae7.jpeg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">Kafka位点主题：_consumer_offsets是什么</div></div><div class="info-2"><div class="info-item-1">和创建的其他主题一样，位移主题就是普通的 Kafka 主题 位移主题中的消息本质为KV结构，  key保存了3部分内容：group ID、主题名、分区号。 value保存格式有3种 位移值 用于保存 Consumer Group 信息：用来注册 Consumer Group 删除 Group 过期位移甚至是删除 Group 的消息：tombstone 消息，即墓碑消息，也称 delete mark。一旦某个 Consumer Group 下的所有 Consumer 实例都停止了，而且它们的位移数据都已被删除时，Kafka 会向位移主题的对应分区写入 tombstone 消息，表明要彻底删除这个 Group 的信息。    位移主题创建时机当 Kafka 集群中的第一个 Consumer 程序启动时，Kafka 会自动创建位移主题。 分区数：如果是 Kafka 自动创建的，按照Broker 端参数 offsets.topic.num.partitions 的取值，它的默认值是 50。 副本数： Broker 端另一个参数...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/kafka/kafka%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96/" title="Kafka如何完成数据持久化"><img class="cover" src="https://vhicool.github.io/kafka/kafka%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96/image-20231219234738266.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-13</div><div class="info-item-2">Kafka如何完成数据持久化</div></div><div class="info-2"><div class="info-item-1">一、概念Data目录存储二进制消息数据 配置项： 1log.dirs=/Users/vhicool/app-template/kafka-2broker/kafka/broker1  kafka日志末尾附加记录，并且每个日志也被分割成segment。segment有助于删除旧记录，提高性能等等。因此，日志是由segment文件组成的记录的逻辑序列。 Kafka 主题被拆分为多个partition，记录将追加到这些partition。每个分区都可以定义为一个工作单元，而不是存储单元，因为它被客户端用来交换记录。分区进一步拆分为多个segment，这些segment是磁盘上的实际文件。拆分为多个segment确实有助于提高性能（当磁盘上的记录被删除或使用者开始从特定偏移量使用时，大型、未分段的文件速度较慢且更容易出错）。查看broker磁盘，每个主题分区都是一个目录，其中包含相应的 segment 文件和其他文件。以...</div></div></div></a><a class="pagination-related" href="/kafka/%E6%97%A0%E6%B6%88%E6%81%AF%E4%B8%A2%E5%A4%B1/" title="Kafka如何保证无消息丢失"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-07</div><div class="info-item-2">Kafka如何保证无消息丢失</div></div><div class="info-2"><div class="info-item-1">Kafka 只对“已提交”的消息（committed message）做有限度的持久化保证。  已提交 Broker 成功地接收到一条消息并写入到日志文件后，它们会告诉生产者程序这条消息已成功提交。此时，这条消息在 Kafka 看来就正式变为“已提交”消息了。  有限度的持久化保证Kafka 不可能保证在任何情况下都做到不丢失消息。假如你的消息保存在 N 个 Kafka Broker 上，那么这个前提条件就是这 N 个 Broker 中至少有 1 个存活。只要这个条件成立，Kafka 就能保证你的这条消息永远不会丢失。   最佳实践 不要使用 producer.send(msg)，而要使用 producer.send(msg, callback)。记住，一定要使用带有回调通知的 send 方法。 设置 acks = all。acks 是 Producer 的一个参数，代表了你对“已提交”消息的定义。如果设置成 all，则表明所有副本 Broker...</div></div></div></a><a class="pagination-related" href="/kafka/%E6%B6%88%E8%B4%B9%E7%BB%84%E6%8F%90%E4%BA%A4%E4%BD%8D%E7%A7%BB/" title="Kafka消费组如何提交位移"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-13</div><div class="info-item-2">Kafka消费组如何提交位移</div></div><div class="info-2"><div class="info-item-1">Consumer 需要向 Kafka 汇报自己的位移数据，这个汇报过程被称为提交位移（Committing Offsets）。Consumer 需要为分配给它的每个分区提交各自的位移数据。 一、位移提交方式从用户的角度来说，位移提交分为自动提交和手动提交；从 Consumer 端的角度来说，位移提交分为同步提交和异步提交。 1. 位移提交控制enable.auto.commit：Consumer 端位移提交配置，默认值true，自动提交位移。 auto.commit.interval.ms：它的默认值是 5 秒，表明 Kafka 每 5 秒会为你自动提交一次位移 2. 自动提交位移Kafka 会保证在开始调用 poll 方法时，提交上次 poll 返回的所有消息。从顺序上来说，poll 方法的逻辑是先提交上一批消息的位移，再处理下一批消息，因此它能保证不出现消费丢失的情况。但自动提交位移的一个问题在于，它可能会出现重复消费 1234567891011121314Properties props = new Properties();    ...</div></div></div></a><a class="pagination-related" href="/kafka/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/" title="Kafka常用命令，日常运维必备"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-07</div><div class="info-item-2">Kafka常用命令，日常运维必备</div></div><div class="info-2"><div class="info-item-1">主题 创建主题  –zookeeper 会绕过 Kafka 的安全体系。这就是说，即使你为 Kafka 集群设置了安全认证，限制了主题的创建，如果你使用 –zookeeper 的命令，依然能成功创建任意主题，不受认证体系的约束  1bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 2 --topic test   直接使用–bootstrap-server 与集群进行交互  1bin/kafka-topics.sh --bootstrap-server broker_host:port --create --topic my_topic_name  --partitions 1 --replication-factor 1  发送消息 1bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test  查询指定topic 1bin/kafka-topics.sh...</div></div></div></a><a class="pagination-related" href="/kafka/%E6%B6%88%E8%B4%B9%E7%BB%84rebalance%E8%BF%87%E7%A8%8B/" title="Kafka消费组如何进行重平衡"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-13</div><div class="info-item-2">Kafka消费组如何进行重平衡</div></div><div class="info-2"><div class="info-item-1">一、概念Rebalance 就是让一个 Consumer Group 下所有的 Consumer 实例就如何消费订阅主题的所有分区达成共识的过程。在 Rebalance 过程中，所有 Consumer 实例共同参与，在协调者组件的帮助下，完成订阅主题分区的分配。在整个过程中，所有实例都不能消费任何消息，因此它对 Consumer 的 TPS 影响很大。 Coordinator 它专门为 Consumer Group 服务，负责为 Group 执行 Rebalance 以及提供位移管理和组成员管理等。Consumer 端应用程序在提交位移时，其实是向 Coordinator 所在的 Broker 提交位移。同样地，当 Consumer 应用启动时，也是向 Coordinator 所在的 Broker 发送各种请求，然后由 Coordinator 负责执行消费者组的注册、成员管理记录等元数据管理操作。 所有 Broker 都有各自的 Coordinator 组件，从broker上找到当前分组的协调器， 你可以理解为找到位移主题所在的broker...</div></div></div></a><a class="pagination-related" href="/kafka/%E4%BD%8D%E7%82%B9%E4%B8%BB%E9%A2%98-_consumer_offsets/" title="Kafka位点主题：_consumer_offsets是什么"><img class="cover" src="https://vhicool.github.io/kafka/%E4%BD%8D%E7%82%B9%E4%B8%BB%E9%A2%98-_consumer_offsets/86a44073aa60ac33e0833e6a9bfd9ae7.jpeg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-07</div><div class="info-item-2">Kafka位点主题：_consumer_offsets是什么</div></div><div class="info-2"><div class="info-item-1">和创建的其他主题一样，位移主题就是普通的 Kafka 主题 位移主题中的消息本质为KV结构，  key保存了3部分内容：group ID、主题名、分区号。 value保存格式有3种 位移值 用于保存 Consumer Group 信息：用来注册 Consumer Group 删除 Group 过期位移甚至是删除 Group 的消息：tombstone 消息，即墓碑消息，也称 delete mark。一旦某个 Consumer Group 下的所有 Consumer 实例都停止了，而且它们的位移数据都已被删除时，Kafka 会向位移主题的对应分区写入 tombstone 消息，表明要彻底删除这个 Group 的信息。    位移主题创建时机当 Kafka 集群中的第一个 Consumer 程序启动时，Kafka 会自动创建位移主题。 分区数：如果是 Kafka 自动创建的，按照Broker 端参数 offsets.topic.num.partitions 的取值，它的默认值是 50。 副本数： Broker 端另一个参数...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%B0%83%E4%BC%98"><span class="toc-text">操作系统调优</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#JVM-%E5%B1%82%E8%B0%83%E4%BC%98"><span class="toc-text">JVM 层调优</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Broker-%E7%AB%AF%E8%B0%83%E4%BC%98"><span class="toc-text">Broker 端调优</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BA%94%E7%94%A8%E5%B1%82%E8%B0%83%E4%BC%98"><span class="toc-text">应用层调优</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87%E8%B0%83%E4%BC%98"><span class="toc-text">性能指标调优</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E8%B0%83%E4%BC%98%E5%90%9E%E5%90%90%E9%87%8F"><span class="toc-text">1. 调优吞吐量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E8%B0%83%E4%BC%98%E5%BB%B6%E6%97%B6"><span class="toc-text">2. 调优延时</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By vhicool</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.5</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>