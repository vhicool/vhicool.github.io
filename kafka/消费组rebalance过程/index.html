<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Kafka消费组如何进行重平衡 | 二九的博客</title><meta name="author" content="vhicool"><meta name="copyright" content="vhicool"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="一、概念Rebalance 就是让一个 Consumer Group 下所有的 Consumer 实例就如何消费订阅主题的所有分区达成共识的过程。在 Rebalance 过程中，所有 Consumer 实例共同参与，在协调者组件的帮助下，完成订阅主题分区的分配。在整个过程中，所有实例都不能消费任何消息，因此它对 Consumer 的 TPS 影响很大。 Coordinator 它专门为 Consu">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka消费组如何进行重平衡">
<meta property="og:url" content="https://vhicool.github.io/kafka/%E6%B6%88%E8%B4%B9%E7%BB%84rebalance%E8%BF%87%E7%A8%8B/index.html">
<meta property="og:site_name" content="二九的博客">
<meta property="og:description" content="一、概念Rebalance 就是让一个 Consumer Group 下所有的 Consumer 实例就如何消费订阅主题的所有分区达成共识的过程。在 Rebalance 过程中，所有 Consumer 实例共同参与，在协调者组件的帮助下，完成订阅主题分区的分配。在整个过程中，所有实例都不能消费任何消息，因此它对 Consumer 的 TPS 影响很大。 Coordinator 它专门为 Consu">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://vhicool.github.io/img/erjiu.jpeg">
<meta property="article:published_time" content="2025-02-23T11:07:37.000Z">
<meta property="article:modified_time" content="2025-07-13T11:28:21.976Z">
<meta property="article:author" content="vhicool">
<meta property="article:tag" content="kafka">
<meta property="article:tag" content="java">
<meta property="article:tag" content="消息中间件">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://vhicool.github.io/img/erjiu.jpeg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Kafka消费组如何进行重平衡",
  "url": "https://vhicool.github.io/kafka/%E6%B6%88%E8%B4%B9%E7%BB%84rebalance%E8%BF%87%E7%A8%8B/",
  "image": "https://vhicool.github.io/img/erjiu.jpeg",
  "datePublished": "2025-02-23T11:07:37.000Z",
  "dateModified": "2025-07-13T11:28:21.976Z",
  "author": [
    {
      "@type": "Person",
      "name": "vhicool",
      "url": "https://vhicool.github.io/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://vhicool.github.io/kafka/%E6%B6%88%E8%B4%B9%E7%BB%84rebalance%E8%BF%87%E7%A8%8B/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Kafka消费组如何进行重平衡',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div class="post" id="body-wrap"><header class="post-bg fixed" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">二九的博客</span></a><a class="nav-page-title" href="/"><span class="site-name">Kafka消费组如何进行重平衡</span></a></span><div id="menus"></div></nav><div id="post-info"><h1 class="post-title">Kafka消费组如何进行重平衡</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-02-23T11:07:37.000Z" title="发表于 2025-02-23 19:07:37">2025-02-23</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-07-13T11:28:21.976Z" title="更新于 2025-07-13 19:28:21">2025-07-13</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/kafka/">kafka</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h2 id="一、概念"><a href="#一、概念" class="headerlink" title="一、概念"></a>一、概念</h2><p>Rebalance 就是让一个 Consumer Group 下所有的 Consumer 实例就如何消费订阅主题的所有分区达成共识的过程。在 Rebalance 过程中，所有 Consumer 实例共同参与，在协调者组件的帮助下，完成订阅主题分区的分配。在整个过程中，所有实例都不能消费任何消息，因此它对 Consumer 的 TPS 影响很大。</p>
<p><strong>Coordinator</strong></p>
<p>它专门为 Consumer Group 服务，负责为 Group 执行 Rebalance 以及提供位移管理和组成员管理等。Consumer 端应用程序在提交位移时，其实是向 Coordinator 所在的 Broker 提交位移。同样地，当 Consumer 应用启动时，也是向 Coordinator 所在的 Broker 发送各种请求，然后由 Coordinator 负责执行消费者组的注册、成员管理记录等元数据管理操作。</p>
<p>所有 Broker 都有各自的 Coordinator 组件，从broker上找到当前分组的协调器， 你可以理解为找到位移主题所在的broker lead副本所存在的节点。</p>
<p><strong>Consumer Group 确定 Coordinator 所在的 Broker 的算法</strong></p>
<ol>
<li>确定由位移主题的哪个分区来保存该 Group 数据：<code>partitionId=Math.abs(groupId.hashCode()%offsetsTopicPartitionCount)</code>。</li>
<li>找出该分区 Leader 副本所在的 Broker，该 Broker 即为对应的 Coordinator</li>
</ol>
<p><strong>实战：</strong> 当 Consumer Group 出现问题，需要快速排查 Broker 端日志时，我们能够根据这个算法准确定位 Coordinator 对应的 Broker，不必一台 Broker 一台 Broker 地盲查</p>
<h2 id="二、Consumer感知Rebalance流程"><a href="#二、Consumer感知Rebalance流程" class="headerlink" title="二、Consumer感知Rebalance流程"></a>二、Consumer感知Rebalance流程</h2><ol>
<li><p>Consumer从broker拉取消息，具体使用<code>KafkaConsumer#poll</code>方法<br>并且此方法会受到客户端rebalance影响，直到Rebalance成功后才会继续拉取消息，也就是说poll方法可能会超时，直到Rebalance成功</p>
</li>
<li><p>向ConsumerCoordinator请求协调器事件，同时确保ConsumerCoordinator已经知晓消费者加入此消费组。具体做了下面的操作</p>
<p>（1）更新上次轮询时间的心跳，以便心跳线程不会由于应用程序不活动离开组，即使（例如）找不到协调员。如果需要，唤醒检测信号线程（上次心跳时间距现在已经超过心跳检测间隔时间）</p>
<p>（2）判断消费客户端是否需要触发ReJoin消费组，满足下面其中一个条件触发ReJoin消费组</p>
<ul>
<li>如果我们执行了任务并且元数据已更改</li>
<li>如果我们的订阅自上次加入以来发生了变化</li>
<li>ReJoin请求已在运行中，或者客户端ReJoin状态为true</li>
</ul>
</li>
<li><p>再次检查与ConsumerCoordinator的链接状态是否正常，如果正常则继续，否则重复<strong>第2步</strong></p>
</li>
<li><p>初始化心跳线程（只会初始化一次）</p>
</li>
<li><p>持续向broker发送<strong>FindCoordinator</strong>请求，直至与coordinator连接成功，超时时间为<code>KafkaConsumer#poll</code>设置时间</p>
</li>
<li><p>执行<code>ConsumerRebalanceListener#onPartitionsRevoked</code>方法，通知Consumer客户端队列即将重平衡</p>
</li>
<li><p>关闭心跳线程，使其无法干扰Join组操作</p>
</li>
<li><p>向coordinator发送<strong>JoinGroup</strong>请求，并修改Consumer状态：UNJOINED &#x3D;&gt; REBALANCING，根据<strong>JoinGroup</strong>响应做出处理：</p>
<ul>
<li><p>成功</p>
<ol>
<li><p>Consumer状态：REBALANCING &#x3D;&gt; STABLE</p>
</li>
<li><p>开启心跳线程</p>
</li>
<li><p>执行<code>ConsumerRebalanceListener#onPartitionsAssigned</code>方法，重平衡完成</p>
</li>
</ol>
<p>日志：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Setting newly assigned partitions:</span><br></pre></td></tr></table></figure>
</li>
<li><p>失败</p>
<p>REBALANCING &#x3D;&gt; UNJOINED</p>
<p>重平衡失败，如果是因为异常不是<code>RetriableException</code>，则抛出异常，否则重试<strong>步骤2</strong></p>
</li>
</ul>
</li>
<li><p>拉下队列消息</p>
</li>
</ol>
<h2 id="三、如何避免-Rebalance"><a href="#三、如何避免-Rebalance" class="headerlink" title="三、如何避免 Rebalance"></a>三、如何避免 Rebalance</h2><h3 id="1-Rebalance-的弊端"><a href="#1-Rebalance-的弊端" class="headerlink" title="1. Rebalance 的弊端"></a>1. Rebalance 的弊端</h3><ul>
<li><p><strong>Rebalance 影响 Consumer 端 TPS</strong><br>在 Rebalance 期间，Consumer 会停下手头的事情，什么也干不了</p>
</li>
<li><p><strong>Rebalance 很慢</strong><br>几百个 Consumer 实例，Rebalance 一次可能需要几个小时</p>
</li>
<li><p><strong>Rebalance 效率不高</strong><br>当前 Kafka 的设计机制决定了每次 Rebalance 时，Group 下的所有成员都要参与进来，而且通常不会考虑局部性原理，但局部性原理对提升系统性能是特别重要的。（0.11.0.0 版本推出了 StickyAssignor，即有粘性的分区分配策略。所谓的有粘性，是指每次 Rebalance 时，该策略会尽可能地保留之前的分配方案，尽量实现分区分配的最小变动）</p>
</li>
</ul>
<h3 id="2-Rebalance-发生的时机"><a href="#2-Rebalance-发生的时机" class="headerlink" title="2. Rebalance 发生的时机"></a>2. Rebalance 发生的时机</h3><ul>
<li>组成员数量发生变化<ul>
<li>增加 Consumer 实例</li>
<li>减少Consumer实例数</li>
</ul>
</li>
<li>订阅主题数量发生变化</li>
<li>订阅主题的分区数发生变化</li>
</ul>
<p><strong>组成员数量发生变化</strong></p>
<ul>
<li><p>增加 Consumer 实例</p>
</li>
<li><p>Consumer实例数减少</p>
<p>现象：</p>
<p>broker端日志会频繁输出类似：(Re)join group</p>
<p>原因：</p>
<ul>
<li><p>Consumer 实例会被 Coordinator 错误地认为“已停止”从而被“踢出”Group<br>每个 Consumer 实例都会定期地向 Coordinator 发送心跳请求，表明它还存活着。某个 Consumer 实例不能及时地发送心跳请求，Coordinator 就会认为该 Consumer 已经“死”了，从而将其从 Group 中移除，然后开启新一轮 Rebalance。</p>
</li>
<li><p>两个 关键参数：</p>
<p><code>session.timeout.ms</code>：默认值是 10，如果 Coordinator 在 10 秒之内没有收到 Group 下某 Consumer 实例的心跳，它就会认为这个 Consumer 实例已经挂了</p>
<p><code>heartbeat.interval.ms</code>：这个值设置得越小，Consumer 实例发送心跳请求的频率就越高。频繁地发送心跳请求会额外消耗带宽资源，但好处是能够更加快速地知晓当前是否开启 Rebalance。 Coordinator通知consumer进行rebalence的方法是将<code>REBALANCE_NEEDED</code>标志封装在心跳包的响应体里。</p>
<p><code>max.poll.interval.ms</code>：它限定了 Consumer 端应用程序两次调用 poll 方法的最大时间间隔。它的默认值是 5 分钟，表示你的 Consumer 程序如果在 5 分钟之内无法消费完 poll 方法返回的消息，那么 Consumer 会主动发起“离开组”的请求，Coordinator 也会开启新一轮 Rebalance。</p>
</li>
</ul>
<p>如何避免：<br><strong>未能及时发送心跳：</strong></p>
<ul>
<li>设置 <code>session.timeout.ms </code>&#x3D; 6s</li>
<li>设置 <code>heartbeat.interval.ms</code> &#x3D; 2s</li>
<li>要保证 Consumer 实例在被判定为“dead”之前，能够发送至少 3 轮的心跳请求，即 session.timeout.ms &gt;&#x3D; 3 * heartbeat.interval.ms。</li>
</ul>
<p><strong>Consumer 消费时间过长：</strong></p>
<ul>
<li><code>max.poll.interval.ms</code>设置时间要大于消费消息处理耗时，如业务处理消息时间为5分钟，那么max.poll.interval.ms要设置为6分钟</li>
</ul>
<p><strong>Consumer 端的 GC 表现</strong></p>
<ul>
<li>客户端出现了频繁的 Full GC 导致的长时间停顿，从而引发了 Rebalance</li>
</ul>
</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://vhicool.github.io">vhicool</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://vhicool.github.io/kafka/%E6%B6%88%E8%B4%B9%E7%BB%84rebalance%E8%BF%87%E7%A8%8B/">https://vhicool.github.io/kafka/%E6%B6%88%E8%B4%B9%E7%BB%84rebalance%E8%BF%87%E7%A8%8B/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://vhicool.github.io" target="_blank">二九的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/kafka/">kafka</a><a class="post-meta__tags" href="/tags/java/">java</a><a class="post-meta__tags" href="/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/">消息中间件</a></div><div class="post-share"><div class="social-share" data-image="/img/erjiu.jpeg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/kafka/%E6%B6%88%E8%B4%B9%E7%BB%84%E6%8F%90%E4%BA%A4%E4%BD%8D%E7%A7%BB/" title="Kafka消费组如何提交位移"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">Kafka消费组如何提交位移</div></div><div class="info-2"><div class="info-item-1">Consumer 需要向 Kafka 汇报自己的位移数据，这个汇报过程被称为提交位移（Committing Offsets）。Consumer 需要为分配给它的每个分区提交各自的位移数据。 一、位移提交方式从用户的角度来说，位移提交分为自动提交和手动提交；从 Consumer 端的角度来说，位移提交分为同步提交和异步提交。 1. 位移提交控制enable.auto.commit：Consumer 端位移提交配置，默认值true，自动提交位移。 auto.commit.interval.ms：它的默认值是 5 秒，表明 Kafka 每 5 秒会为你自动提交一次位移 2. 自动提交位移Kafka 会保证在开始调用 poll 方法时，提交上次 poll 返回的所有消息。从顺序上来说，poll 方法的逻辑是先提交上一批消息的位移，再处理下一批消息，因此它能保证不出现消费丢失的情况。但自动提交位移的一个问题在于，它可能会出现重复消费 1234567891011121314Properties props = new Properties();    ...</div></div></div></a><a class="pagination-related" href="/kafka/kafka%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96/" title="Kafka如何完成数据持久化"><img class="cover" src="https://vhicool.github.io/kafka/kafka%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96/image-20231219234738266.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">Kafka如何完成数据持久化</div></div><div class="info-2"><div class="info-item-1">一、概念Data目录存储二进制消息数据 配置项： 1log.dirs=/Users/vhicool/app-template/kafka-2broker/kafka/broker1  kafka日志末尾附加记录，并且每个日志也被分割成segment。segment有助于删除旧记录，提高性能等等。因此，日志是由segment文件组成的记录的逻辑序列。 Kafka 主题被拆分为多个partition，记录将追加到这些partition。每个分区都可以定义为一个工作单元，而不是存储单元，因为它被客户端用来交换记录。分区进一步拆分为多个segment，这些segment是磁盘上的实际文件。拆分为多个segment确实有助于提高性能（当磁盘上的记录被删除或使用者开始从特定偏移量使用时，大型、未分段的文件速度较慢且更容易出错）。查看broker磁盘，每个主题分区都是一个目录，其中包含相应的 segment 文件和其他文件。以...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/kafka/kafka%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96/" title="Kafka如何完成数据持久化"><img class="cover" src="https://vhicool.github.io/kafka/kafka%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96/image-20231219234738266.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-03</div><div class="info-item-2">Kafka如何完成数据持久化</div></div><div class="info-2"><div class="info-item-1">一、概念Data目录存储二进制消息数据 配置项： 1log.dirs=/Users/vhicool/app-template/kafka-2broker/kafka/broker1  kafka日志末尾附加记录，并且每个日志也被分割成segment。segment有助于删除旧记录，提高性能等等。因此，日志是由segment文件组成的记录的逻辑序列。 Kafka 主题被拆分为多个partition，记录将追加到这些partition。每个分区都可以定义为一个工作单元，而不是存储单元，因为它被客户端用来交换记录。分区进一步拆分为多个segment，这些segment是磁盘上的实际文件。拆分为多个segment确实有助于提高性能（当磁盘上的记录被删除或使用者开始从特定偏移量使用时，大型、未分段的文件速度较慢且更容易出错）。查看broker磁盘，每个主题分区都是一个目录，其中包含相应的 segment 文件和其他文件。以...</div></div></div></a><a class="pagination-related" href="/kafka/kafka%E8%B0%83%E4%BC%98/" title="kafka性能调优"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-17</div><div class="info-item-2">kafka性能调优</div></div><div class="info-2"><div class="info-item-1">操作系统调优 挂载（Mount）文件系统时禁掉 atime 更新 atime 的全称是 access time，记录的是文件最后被访问的时间。记录 atime 需要操作系统访问 inode 资源，而禁掉 atime 可以避免 inode 访问时间的写入操作，减少文件系统的写操作数。你可以执行 mount -o noatime 命令进行设置。  文件系统选择  至少选择ext4 或 XFS，尤其是 XFS 文件系统，它具有高性能、高伸缩性等特点，特别适用于生产服务器。  ZFS 多级缓存的机制能够帮助 Kafka 改善 I&#x2F;O 性能    swap 空间的设置 建议将swappiness 设置成一个很小的值，比如 1～10 之间，以防止 Linux 的 OOM Killer 开启随意杀掉进程 临时设置：sudo sysctl vm.swappiness&#x3D;N 永久设置：修改 &#x2F;etc&#x2F;sysctl.conf 文件，增加 vm.swappiness&#x3D;N，然后重启机器  ulimit -n 如果设置得太小，你会碰到 Too Many...</div></div></div></a><a class="pagination-related" href="/kafka/%E6%B6%88%E8%B4%B9%E7%BB%84%E6%8F%90%E4%BA%A4%E4%BD%8D%E7%A7%BB/" title="Kafka消费组如何提交位移"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-02-13</div><div class="info-item-2">Kafka消费组如何提交位移</div></div><div class="info-2"><div class="info-item-1">Consumer 需要向 Kafka 汇报自己的位移数据，这个汇报过程被称为提交位移（Committing Offsets）。Consumer 需要为分配给它的每个分区提交各自的位移数据。 一、位移提交方式从用户的角度来说，位移提交分为自动提交和手动提交；从 Consumer 端的角度来说，位移提交分为同步提交和异步提交。 1. 位移提交控制enable.auto.commit：Consumer 端位移提交配置，默认值true，自动提交位移。 auto.commit.interval.ms：它的默认值是 5 秒，表明 Kafka 每 5 秒会为你自动提交一次位移 2. 自动提交位移Kafka 会保证在开始调用 poll 方法时，提交上次 poll 返回的所有消息。从顺序上来说，poll 方法的逻辑是先提交上一批消息的位移，再处理下一批消息，因此它能保证不出现消费丢失的情况。但自动提交位移的一个问题在于，它可能会出现重复消费 1234567891011121314Properties props = new Properties();    ...</div></div></div></a><a class="pagination-related" href="/kafka/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/" title="Kafka常用命令，日常运维必备"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-01-07</div><div class="info-item-2">Kafka常用命令，日常运维必备</div></div><div class="info-2"><div class="info-item-1">主题 创建主题  –zookeeper 会绕过 Kafka 的安全体系。这就是说，即使你为 Kafka 集群设置了安全认证，限制了主题的创建，如果你使用 –zookeeper 的命令，依然能成功创建任意主题，不受认证体系的约束  1bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 2 --topic test   直接使用–bootstrap-server 与集群进行交互  1bin/kafka-topics.sh --bootstrap-server broker_host:port --create --topic my_topic_name  --partitions 1 --replication-factor 1  发送消息 1bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test  查询指定topic 1bin/kafka-topics.sh...</div></div></div></a><a class="pagination-related" href="/kafka/%E6%97%A0%E6%B6%88%E6%81%AF%E4%B8%A2%E5%A4%B1/" title="Kafka如何保证无消息丢失"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-01-25</div><div class="info-item-2">Kafka如何保证无消息丢失</div></div><div class="info-2"><div class="info-item-1">Kafka 只对“已提交”的消息（committed message）做有限度的持久化保证。  已提交 Broker 成功地接收到一条消息并写入到日志文件后，它们会告诉生产者程序这条消息已成功提交。此时，这条消息在 Kafka 看来就正式变为“已提交”消息了。  有限度的持久化保证Kafka 不可能保证在任何情况下都做到不丢失消息。假如你的消息保存在 N 个 Kafka Broker 上，那么这个前提条件就是这 N 个 Broker 中至少有 1 个存活。只要这个条件成立，Kafka 就能保证你的这条消息永远不会丢失。   最佳实践 不要使用 producer.send(msg)，而要使用 producer.send(msg, callback)。记住，一定要使用带有回调通知的 send 方法。 设置 acks = all。acks 是 Producer 的一个参数，代表了你对“已提交”消息的定义。如果设置成 all，则表明所有副本 Broker...</div></div></div></a><a class="pagination-related" href="/kafka/%E4%BD%8D%E7%82%B9%E4%B8%BB%E9%A2%98-_consumer_offsets/" title="Kafka位点主题：_consumer_offsets是什么"><img class="cover" src="https://vhicool.github.io/kafka/%E4%BD%8D%E7%82%B9%E4%B8%BB%E9%A2%98-_consumer_offsets/86a44073aa60ac33e0833e6a9bfd9ae7.jpeg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-02-07</div><div class="info-item-2">Kafka位点主题：_consumer_offsets是什么</div></div><div class="info-2"><div class="info-item-1">和创建的其他主题一样，位移主题就是普通的 Kafka 主题 位移主题中的消息本质为KV结构，  key保存了3部分内容：group ID、主题名、分区号。 value保存格式有3种 位移值 用于保存 Consumer Group 信息：用来注册 Consumer Group 删除 Group 过期位移甚至是删除 Group 的消息：tombstone 消息，即墓碑消息，也称 delete mark。一旦某个 Consumer Group 下的所有 Consumer 实例都停止了，而且它们的位移数据都已被删除时，Kafka 会向位移主题的对应分区写入 tombstone 消息，表明要彻底删除这个 Group 的信息。    位移主题创建时机当 Kafka 集群中的第一个 Consumer 程序启动时，Kafka 会自动创建位移主题。 分区数：如果是 Kafka 自动创建的，按照Broker 端参数 offsets.topic.num.partitions 的取值，它的默认值是 50。 副本数： Broker 端另一个参数...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E6%A6%82%E5%BF%B5"><span class="toc-text">一、概念</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81Consumer%E6%84%9F%E7%9F%A5Rebalance%E6%B5%81%E7%A8%8B"><span class="toc-text">二、Consumer感知Rebalance流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8D-Rebalance"><span class="toc-text">三、如何避免 Rebalance</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Rebalance-%E7%9A%84%E5%BC%8A%E7%AB%AF"><span class="toc-text">1. Rebalance 的弊端</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Rebalance-%E5%8F%91%E7%94%9F%E7%9A%84%E6%97%B6%E6%9C%BA"><span class="toc-text">2. Rebalance 发生的时机</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By vhicool</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.5</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>