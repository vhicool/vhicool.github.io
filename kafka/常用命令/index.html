<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Kafka常用命令，日常运维必备 | 二九的博客</title><meta name="author" content="vhicool"><meta name="copyright" content="vhicool"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="主题 创建主题  –zookeeper 会绕过 Kafka 的安全体系。这就是说，即使你为 Kafka 集群设置了安全认证，限制了主题的创建，如果你使用 –zookeeper 的命令，依然能成功创建任意主题，不受认证体系的约束  1bin&#x2F;kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --par">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka常用命令，日常运维必备">
<meta property="og:url" content="https://vhicool.github.io/kafka/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/index.html">
<meta property="og:site_name" content="二九的博客">
<meta property="og:description" content="主题 创建主题  –zookeeper 会绕过 Kafka 的安全体系。这就是说，即使你为 Kafka 集群设置了安全认证，限制了主题的创建，如果你使用 –zookeeper 的命令，依然能成功创建任意主题，不受认证体系的约束  1bin&#x2F;kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --par">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://vhicool.github.io/img/erjiu.jpeg">
<meta property="article:published_time" content="2025-01-07T14:05:55.000Z">
<meta property="article:modified_time" content="2025-07-13T11:26:56.254Z">
<meta property="article:author" content="vhicool">
<meta property="article:tag" content="kafka">
<meta property="article:tag" content="java">
<meta property="article:tag" content="消息中间件">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://vhicool.github.io/img/erjiu.jpeg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Kafka常用命令，日常运维必备",
  "url": "https://vhicool.github.io/kafka/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/",
  "image": "https://vhicool.github.io/img/erjiu.jpeg",
  "datePublished": "2025-01-07T14:05:55.000Z",
  "dateModified": "2025-07-13T11:26:56.254Z",
  "author": [
    {
      "@type": "Person",
      "name": "vhicool",
      "url": "https://vhicool.github.io/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://vhicool.github.io/kafka/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Kafka常用命令，日常运维必备',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div class="post" id="body-wrap"><header class="post-bg fixed" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">二九的博客</span></a><a class="nav-page-title" href="/"><span class="site-name">Kafka常用命令，日常运维必备</span></a></span><div id="menus"></div></nav><div id="post-info"><h1 class="post-title">Kafka常用命令，日常运维必备</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-01-07T14:05:55.000Z" title="发表于 2025-01-07 22:05:55">2025-01-07</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-07-13T11:26:56.254Z" title="更新于 2025-07-13 19:26:56">2025-07-13</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/kafka/">kafka</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h2 id="主题"><a href="#主题" class="headerlink" title="主题"></a>主题</h2><ul>
<li><p>创建主题</p>
<ol>
<li>–zookeeper 会绕过 Kafka 的安全体系。这就是说，即使你为 Kafka 集群设置了安全认证，限制了主题的创建，如果你使用 –zookeeper 的命令，依然能成功创建任意主题，不受认证体系的约束</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 2 --topic test</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>直接使用–bootstrap-server 与集群进行交互</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --bootstrap-server broker_host:port --create --topic my_topic_name  --partitions 1 --replication-factor 1</span><br></pre></td></tr></table></figure>
</li>
<li><p>发送消息</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test</span><br></pre></td></tr></table></figure>
</li>
<li><p>查询指定topic</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --zookeeper localhost:2181 --topic test --describe</span><br></pre></td></tr></table></figure>
</li>
<li><p>查询所有主题的列表</p>
<blockquote>
<p>仍然区分使用<code>--zookeeper</code>和<code>--broker-list</code>,如果指定了 –bootstrap-server，那么这条命令就会受到安全认证体系的约束，即对 发起者进行权限验证，然后返回它能看到的主题。否则，如果指定 –zookeeper 参数，那么默认会返回集群中所有的主题详细数据</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --zookeeper localhost:2181 broker_host:port --list</span><br></pre></td></tr></table></figure>
</li>
<li><p>查询topic最小分片最小偏移量（–time -1 是最大变异量）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list localhost:9092  --topic test --time -2</span><br></pre></td></tr></table></figure>
</li>
<li><p>删除主题</p>
<blockquote>
<p>异步删除</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/kafka-topics.sh --delete --zookeeper localhost:2181 --topic test</span><br></pre></td></tr></table></figure>
</li>
<li><p>查询主题offset</p>
<blockquote>
<p>–time参数</p>
<ul>
<li>-1：最大offset</li>
<li>-2：最小offset</li>
</ul>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list localhost:9092 -topic test --time -2</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改主题分区（分区扩容）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/kafka-topics.sh --alter --zookeeper localhost:2181 --topic test --partitions 3</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="消息"><a href="#消息" class="headerlink" title="消息"></a>消息</h3><ul>
<li><p>主题消息总数</p>
<p>最大偏移减去最小偏移量值</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">最小偏移</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka-host:port --<span class="keyword">time</span> -2 --topic test-topic</span></span><br><span class="line"></span><br><span class="line">test-topic:0:0</span><br><span class="line">test-topic:1:0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">最大偏移</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka-host:port --<span class="keyword">time</span> -1 --topic test-topic</span></span><br><span class="line"></span><br><span class="line">test-topic:0:5500000</span><br><span class="line">test-topic:1:5500000</span><br></pre></td></tr></table></figure>

<ul>
<li><p>消息文件数据</p>
<p>查看消息文件信息</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">bin/kafka-dump-log.sh --files ../data_dir/kafka_1/test-topic-1/00000000000000000000.<span class="built_in">log</span></span></span><br><span class="line"></span><br><span class="line">Dumping ../data_dir/kafka_1/test-topic-1/00000000000000000000.log</span><br><span class="line">Starting offset: 0</span><br><span class="line">baseOffset: 0 lastOffset: 14 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 CreateTime: 1561597044933 size: 1237 magic: 2 compresscodec: LZ4 crc: 646766737 isvalid: true</span><br><span class="line">baseOffset: 15 lastOffset: 29 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 1237 CreateTime: 1561597044934 size: 1237 magic: 2 compresscodec: LZ4 crc: 3751986433 isvalid: true</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<p>​	查询消息文件实际内容</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">bin/kafka-dump-log.sh --files ../data_dir/kafka_1/test-topic-1/00000000000000000000.<span class="built_in">log</span> --deep-iteration --print-data-log</span></span><br></pre></td></tr></table></figure>







<h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><ul>
<li><p>查看这个 topic 设置的参数</p>
<blockquote>
<p>设置常规的主题级别参数，还是使用 <code>--zookeeper</code>。设置动态参数指定 <code>--bootstrap-server</code> 参数</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/kafka-configs.sh --zookeeper localhost:2181  --entity-type topics --entity-name test-topic --describe </span><br></pre></td></tr></table></figure>
</li>
<li><p>设置配置参数</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/kafka-configs.sh --zookeeper localhost:2181  --entity-type topics --entity-name test-topic --alter --add-config max.message.bytes=10485760</span><br></pre></td></tr></table></figure>
</li>
<li><p>变更副本数</p>
</li>
<li><p>修改主题限速</p>
<blockquote>
<p>主题test，让该主题各个分区的 Leader 副本和 Follower 副本在处理副本同步时，不得占用超过 100MBps 的带宽</p>
</blockquote>
<ol>
<li><p><strong>broker限速配置</strong></p>
<blockquote>
<p>Leader 副本和 Follower 副本使用的带宽。有时候，我们想要让某个主题的副本在执行副本同步机制时，不要消耗过多的带宽</p>
</blockquote>
</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-configs.sh --zookeeper zookeeper_host:port --alter --add-config &#x27;leader.replication.throttled.rate=104857600,follower.replication.throttled.rate=104857600&#x27; --entity-type brokers --entity-name 0</span><br></pre></td></tr></table></figure>

<ul>
<li>–entity-type：限速类型为broker</li>
<li>–entity-name : Broker ID,倘若该主题的副本分别在 0、1、2、3 多个 Broker 上，那么还要依次为 Broker 1、2、3 执行这条命令</li>
</ul>
<ol start="2">
<li><p><strong>主题限速</strong></p>
<blockquote>
<p>我们想要为所有副本都设置限速，因此统一使用通配符 *</p>
</blockquote>
</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-configs.sh --zookeeper zookeeper_host:port --alter --add-config &#x27;leader.replication.throttled.replicas=*,follower.replication.throttled.replicas=*&#x27; --entity-type topics --entity-name test</span><br></pre></td></tr></table></figure>

<ul>
<li>–entity-type：限速类型为主题</li>
<li>–entity-name ：主题名称</li>
</ul>
</li>
<li><p>主题分区迁移</p>
</li>
</ul>
<h3 id="特殊主题的管理与运维"><a href="#特殊主题的管理与运维" class="headerlink" title="特殊主题的管理与运维"></a>特殊主题的管理与运维</h3><ul>
<li><p>__consumer_offsets</p>
<p><strong>副本数</strong></p>
<p>Kafka 0.11 之前：__consumer_offsets主题的副本数为：min(Broker台数 , Broker端参数<code>offsets.topic.replication.factor</code> 值)。如果出现Broker的<code>offsets.topic.replication.factor</code> 设置为3，但是__consumer_offsets主题的副本数是1，是因为这个主题是在只有一台 Broker 启动时被创建<br>Kafka-0.11 版本之后：Kafka 会严格遵守 <code>offsets.topic.replication.factor</code>值。如果当前运行的 Broker 数量小于 offsets.topic.replication.factor 值，Kafka 会创建主题失败，并显式抛出异常</p>
</li>
<li><p>将副本数从1增加到3</p>
<ol>
<li><p>创建一个 json 文件，显式提供 50 个分区对应的副本数</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;version&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span> <span class="attr">&quot;partitions&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span></span><br><span class="line"> <span class="punctuation">&#123;</span><span class="attr">&quot;topic&quot;</span><span class="punctuation">:</span><span class="string">&quot;__consumer_offsets&quot;</span><span class="punctuation">,</span><span class="attr">&quot;partition&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;replicas&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="number">0</span><span class="punctuation">,</span><span class="number">1</span><span class="punctuation">,</span><span class="number">2</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span> </span><br><span class="line">  <span class="punctuation">&#123;</span><span class="attr">&quot;topic&quot;</span><span class="punctuation">:</span><span class="string">&quot;__consumer_offsets&quot;</span><span class="punctuation">,</span><span class="attr">&quot;partition&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;replicas&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="number">0</span><span class="punctuation">,</span><span class="number">2</span><span class="punctuation">,</span><span class="number">1</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span><span class="attr">&quot;topic&quot;</span><span class="punctuation">:</span><span class="string">&quot;__consumer_offsets&quot;</span><span class="punctuation">,</span><span class="attr">&quot;partition&quot;</span><span class="punctuation">:</span><span class="number">2</span><span class="punctuation">,</span><span class="attr">&quot;replicas&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">,</span><span class="number">0</span><span class="punctuation">,</span><span class="number">2</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span><span class="attr">&quot;topic&quot;</span><span class="punctuation">:</span><span class="string">&quot;__consumer_offsets&quot;</span><span class="punctuation">,</span><span class="attr">&quot;partition&quot;</span><span class="punctuation">:</span><span class="number">3</span><span class="punctuation">,</span><span class="attr">&quot;replicas&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">,</span><span class="number">2</span><span class="punctuation">,</span><span class="number">0</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  ...</span><br><span class="line">  <span class="punctuation">&#123;</span><span class="attr">&quot;topic&quot;</span><span class="punctuation">:</span><span class="string">&quot;__consumer_offsets&quot;</span><span class="punctuation">,</span><span class="attr">&quot;partition&quot;</span><span class="punctuation">:</span><span class="number">49</span><span class="punctuation">,</span><span class="attr">&quot;replicas&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="number">0</span><span class="punctuation">,</span><span class="number">1</span><span class="punctuation">,</span><span class="number">2</span><span class="punctuation">]</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">]</span><span class="punctuation">&#125;</span>`</span><br></pre></td></tr></table></figure>
</li>
<li><p>执行 kafka-reassign-partitions 脚本</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-reassign-partitions.sh --zookeeper zookeeper_host:port --reassignment-json-file reassign.json --execute</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><p>查看消费者组提交的位移数据</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh --bootstrap-server kafka_host:port --topic __consumer_offsets --formatter &quot;kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageFormatter&quot; --from-beginning --max-messages 10</span><br></pre></td></tr></table></figure>
</li>
<li><p>消费者组的状态信息</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh --bootstrap-server kafka_host:port --topic __consumer_offsets --formatter &quot;kafka.coordinator.group.GroupMetadataManager\$GroupMetadataMessageFormatter&quot; --from-beginning --max-messages 10</span><br></pre></td></tr></table></figure></li>
</ul>
<p><strong>对于内部主题 <code>__transaction_state</code> 而言，方法是相同，只需要指定 <code>kafka.coordinator.transaction.TransactionLog\$TransactionLogMessageFormatter </code>即可</strong></p>
<h3 id="常见主题错误处理"><a href="#常见主题错误处理" class="headerlink" title="常见主题错误处理"></a>常见主题错误处理</h3><ul>
<li><p>主题删除失败</p>
<p>现象：执行删除主题命令后，磁盘的主题分区并没有被删除</p>
<p>原因：</p>
<ol>
<li><p>副本所在的 Broker 宕机了</p>
<p>解决方法：重启对应的 Broker 之后，删除操作就能自动恢复</p>
</li>
<li><p>待删除主题的部分分区依然在执行迁移过程</p>
<p>解决方法：</p>
<ol>
<li>手动删除 ZooKeeper 节点 &#x2F;admin&#x2F;delete_topics 下以待删除主题为名的 znode</li>
<li>手动删除该主题在磁盘上的分区目录</li>
<li>在 ZooKeeper 中执行 rmr &#x2F;controller，触发 Controller 重选举，刷新 Controller 缓存<br><em><strong>可能造成大面积的分区 Leader 重选举</strong>，事实上，仅仅执行前两步也是可以的，只是 Controller 缓存中没有清空待删除主题罢了，不影响使用</em></li>
</ol>
</li>
</ol>
</li>
<li><p>__consumer_offsets 占用太多的磁盘</p>
<p>原因：<br>jstack 命令查看一下 kafka-log-cleaner-thread 前缀的线程状态。通常情况下，这都是因为该线程挂掉了，无法及时清理此内部主题<br>解决方案：重启相应的 Broker</p>
</li>
</ul>
<h3 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h3><ul>
<li>为什么 Kafka 不允许减少分区数<br>因为多个broker节点都冗余有分区的数据，减少分区数需要操作多个broker且需要迁移该分区数据到其他分区。offset确认中，还在发过来的路上，结果分区没了。这个分区所有的历史消息数据也要被迁移到别的Broker上，千亿规模太大的话，会造成Broker卡顿，而且这些数据跟目标Broker上的原有数据还要排序重写，否则就破坏了Kafka分区内的消息的有序性</li>
</ul>
<h2 id="消费组"><a href="#消费组" class="headerlink" title="消费组"></a>消费组</h2><ul>
<li><p>消费消息</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh  --bootstrap-server localhost:9092 --topic test --from-beginning</span><br></pre></td></tr></table></figure>
</li>
<li><p>消息回溯</p>
<ul>
<li>Earliest</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-earliest –execute</span><br></pre></td></tr></table></figure>

<ul>
<li>Latest</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-latest --execute</span><br></pre></td></tr></table></figure>

<ul>
<li>当前位置</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-consumer-groups.sh --bootstrap-server 10.196.39.133:9092 --group test_consumer --reset-offsets --topic test_topic --to-current --execute</span><br></pre></td></tr></table></figure>

<ul>
<li>Specified-Offset</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics --to-offset &lt;offset&gt; --execute</span><br></pre></td></tr></table></figure>

<ul>
<li>多少消息之前</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --shift-by &lt;offset_N&gt; --execute</span><br></pre></td></tr></table></figure>

<ul>
<li>指定时间</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --to-datetime 2019-06-20T20:00:00.000 --execute</span><br></pre></td></tr></table></figure>

<ul>
<li>多长时间之前</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --by-duration PT0H30M0S --execute</span><br></pre></td></tr></table></figure>


</li>
<li><p>查询所有消费组</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list</span><br></pre></td></tr></table></figure>
</li>
<li><p>查询指定消费组状态</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group cainiao11_forecast --describe</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看位点消费组提交offset明细</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic  __consumer_offsets --formatter &quot;kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageFormatter&quot;</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="压测"><a href="#压测" class="headerlink" title="压测"></a>压测</h2><ul>
<li>测试生产者性能</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-producer-perf-test.sh --topic test-topic --num-records 10000000 --throughput -1 --record-size 1024 --producer-props bootstrap.servers=kafka-host:port acks=-1 linger.ms=2000 compression.type=lz4</span><br></pre></td></tr></table></figure>



<ul>
<li>测试消费着性能</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-consumer-perf-test.sh --broker-list kafka-host:port --messages 10000000 --topic test-topic</span><br></pre></td></tr></table></figure>



</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://vhicool.github.io">vhicool</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://vhicool.github.io/kafka/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/">https://vhicool.github.io/kafka/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://vhicool.github.io" target="_blank">二九的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/kafka/">kafka</a><a class="post-meta__tags" href="/tags/java/">java</a><a class="post-meta__tags" href="/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/">消息中间件</a></div><div class="post-share"><div class="social-share" data-image="/img/erjiu.jpeg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/flink/flink-start/" title="flink快速开始"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">flink快速开始</div></div><div class="info-2"><div class="info-item-1">快速开始1. 基于flink DataStream flink本身提供了丰富的数据读取、转换、写入api，我们可以创建DataStream，并对DataStream进行处理，实现数据处理  运行环境  java8  flink-12.2  maven Flink仓库 1234567891011121314151617 &lt;properties&gt;        &lt;flink.version&gt;1.12.2&lt;/flink.version&gt;        &lt;scala.binary.version&gt;2.11&lt;/scala.binary.version&gt;&lt;/properties&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;           ...</div></div></div></a><a class="pagination-related" href="/kafka/%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5/" title="Kafka分区策略有哪些"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">Kafka分区策略有哪些</div></div><div class="info-2"><div class="info-item-1">分区策略1. 轮询策略  也称 Round-robin 策略，即顺序分配。比如一个主题下有 3 个分区，那么第一条消息被发送到分区 0，第二条被发送到分区 1，第三条被发送到分区 2，以此类推。当生产第 4 条消息时又会重新开始，即将其分配到分区 0，就像下面这张图展示的那样。     这就是所谓的轮询策略。轮询策略是 Kafka Java 生产者 API 默认提供的分区策略。如果你未指定partitioner.class参数，那么你的生产者程序会按照轮询的方式在主题的所有分区间均匀地“码放”消息。轮询策略有非常优秀的负载均衡表现，它总是能保证消息最大限度地被平均分配到所有分区上，故默认情况下它是最合理的分区策略，也是我们最常用的分区策略之一。   1int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster);  2. 随机策略 ...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/kafka/kafka%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96/" title="Kafka如何完成数据持久化"><img class="cover" src="https://vhicool.github.io/kafka/kafka%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96/image-20231219234738266.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-03</div><div class="info-item-2">Kafka如何完成数据持久化</div></div><div class="info-2"><div class="info-item-1">一、概念Data目录存储二进制消息数据 配置项： 1log.dirs=/Users/vhicool/app-template/kafka-2broker/kafka/broker1  kafka日志末尾附加记录，并且每个日志也被分割成segment。segment有助于删除旧记录，提高性能等等。因此，日志是由segment文件组成的记录的逻辑序列。 Kafka 主题被拆分为多个partition，记录将追加到这些partition。每个分区都可以定义为一个工作单元，而不是存储单元，因为它被客户端用来交换记录。分区进一步拆分为多个segment，这些segment是磁盘上的实际文件。拆分为多个segment确实有助于提高性能（当磁盘上的记录被删除或使用者开始从特定偏移量使用时，大型、未分段的文件速度较慢且更容易出错）。查看broker磁盘，每个主题分区都是一个目录，其中包含相应的 segment 文件和其他文件。以...</div></div></div></a><a class="pagination-related" href="/kafka/kafka%E8%B0%83%E4%BC%98/" title="kafka性能调优"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-17</div><div class="info-item-2">kafka性能调优</div></div><div class="info-2"><div class="info-item-1">操作系统调优 挂载（Mount）文件系统时禁掉 atime 更新 atime 的全称是 access time，记录的是文件最后被访问的时间。记录 atime 需要操作系统访问 inode 资源，而禁掉 atime 可以避免 inode 访问时间的写入操作，减少文件系统的写操作数。你可以执行 mount -o noatime 命令进行设置。  文件系统选择  至少选择ext4 或 XFS，尤其是 XFS 文件系统，它具有高性能、高伸缩性等特点，特别适用于生产服务器。  ZFS 多级缓存的机制能够帮助 Kafka 改善 I&#x2F;O 性能    swap 空间的设置 建议将swappiness 设置成一个很小的值，比如 1～10 之间，以防止 Linux 的 OOM Killer 开启随意杀掉进程 临时设置：sudo sysctl vm.swappiness&#x3D;N 永久设置：修改 &#x2F;etc&#x2F;sysctl.conf 文件，增加 vm.swappiness&#x3D;N，然后重启机器  ulimit -n 如果设置得太小，你会碰到 Too Many...</div></div></div></a><a class="pagination-related" href="/kafka/%E6%B6%88%E8%B4%B9%E7%BB%84rebalance%E8%BF%87%E7%A8%8B/" title="Kafka消费组如何进行重平衡"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-02-23</div><div class="info-item-2">Kafka消费组如何进行重平衡</div></div><div class="info-2"><div class="info-item-1">一、概念Rebalance 就是让一个 Consumer Group 下所有的 Consumer 实例就如何消费订阅主题的所有分区达成共识的过程。在 Rebalance 过程中，所有 Consumer 实例共同参与，在协调者组件的帮助下，完成订阅主题分区的分配。在整个过程中，所有实例都不能消费任何消息，因此它对 Consumer 的 TPS 影响很大。 Coordinator 它专门为 Consumer Group 服务，负责为 Group 执行 Rebalance 以及提供位移管理和组成员管理等。Consumer 端应用程序在提交位移时，其实是向 Coordinator 所在的 Broker 提交位移。同样地，当 Consumer 应用启动时，也是向 Coordinator 所在的 Broker 发送各种请求，然后由 Coordinator 负责执行消费者组的注册、成员管理记录等元数据管理操作。 所有 Broker 都有各自的 Coordinator 组件，从broker上找到当前分组的协调器， 你可以理解为找到位移主题所在的broker...</div></div></div></a><a class="pagination-related" href="/kafka/%E6%B6%88%E8%B4%B9%E7%BB%84%E6%8F%90%E4%BA%A4%E4%BD%8D%E7%A7%BB/" title="Kafka消费组如何提交位移"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-02-13</div><div class="info-item-2">Kafka消费组如何提交位移</div></div><div class="info-2"><div class="info-item-1">Consumer 需要向 Kafka 汇报自己的位移数据，这个汇报过程被称为提交位移（Committing Offsets）。Consumer 需要为分配给它的每个分区提交各自的位移数据。 一、位移提交方式从用户的角度来说，位移提交分为自动提交和手动提交；从 Consumer 端的角度来说，位移提交分为同步提交和异步提交。 1. 位移提交控制enable.auto.commit：Consumer 端位移提交配置，默认值true，自动提交位移。 auto.commit.interval.ms：它的默认值是 5 秒，表明 Kafka 每 5 秒会为你自动提交一次位移 2. 自动提交位移Kafka 会保证在开始调用 poll 方法时，提交上次 poll 返回的所有消息。从顺序上来说，poll 方法的逻辑是先提交上一批消息的位移，再处理下一批消息，因此它能保证不出现消费丢失的情况。但自动提交位移的一个问题在于，它可能会出现重复消费 1234567891011121314Properties props = new Properties();    ...</div></div></div></a><a class="pagination-related" href="/kafka/%E6%97%A0%E6%B6%88%E6%81%AF%E4%B8%A2%E5%A4%B1/" title="Kafka如何保证无消息丢失"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-01-25</div><div class="info-item-2">Kafka如何保证无消息丢失</div></div><div class="info-2"><div class="info-item-1">Kafka 只对“已提交”的消息（committed message）做有限度的持久化保证。  已提交 Broker 成功地接收到一条消息并写入到日志文件后，它们会告诉生产者程序这条消息已成功提交。此时，这条消息在 Kafka 看来就正式变为“已提交”消息了。  有限度的持久化保证Kafka 不可能保证在任何情况下都做到不丢失消息。假如你的消息保存在 N 个 Kafka Broker 上，那么这个前提条件就是这 N 个 Broker 中至少有 1 个存活。只要这个条件成立，Kafka 就能保证你的这条消息永远不会丢失。   最佳实践 不要使用 producer.send(msg)，而要使用 producer.send(msg, callback)。记住，一定要使用带有回调通知的 send 方法。 设置 acks = all。acks 是 Producer 的一个参数，代表了你对“已提交”消息的定义。如果设置成 all，则表明所有副本 Broker...</div></div></div></a><a class="pagination-related" href="/kafka/%E4%BD%8D%E7%82%B9%E4%B8%BB%E9%A2%98-_consumer_offsets/" title="Kafka位点主题：_consumer_offsets是什么"><img class="cover" src="https://vhicool.github.io/kafka/%E4%BD%8D%E7%82%B9%E4%B8%BB%E9%A2%98-_consumer_offsets/86a44073aa60ac33e0833e6a9bfd9ae7.jpeg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-02-07</div><div class="info-item-2">Kafka位点主题：_consumer_offsets是什么</div></div><div class="info-2"><div class="info-item-1">和创建的其他主题一样，位移主题就是普通的 Kafka 主题 位移主题中的消息本质为KV结构，  key保存了3部分内容：group ID、主题名、分区号。 value保存格式有3种 位移值 用于保存 Consumer Group 信息：用来注册 Consumer Group 删除 Group 过期位移甚至是删除 Group 的消息：tombstone 消息，即墓碑消息，也称 delete mark。一旦某个 Consumer Group 下的所有 Consumer 实例都停止了，而且它们的位移数据都已被删除时，Kafka 会向位移主题的对应分区写入 tombstone 消息，表明要彻底删除这个 Group 的信息。    位移主题创建时机当 Kafka 集群中的第一个 Consumer 程序启动时，Kafka 会自动创建位移主题。 分区数：如果是 Kafka 自动创建的，按照Broker 端参数 offsets.topic.num.partitions 的取值，它的默认值是 50。 副本数： Broker 端另一个参数...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BB%E9%A2%98"><span class="toc-text">主题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E6%81%AF"><span class="toc-text">消息</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE"><span class="toc-text">配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%B9%E6%AE%8A%E4%B8%BB%E9%A2%98%E7%9A%84%E7%AE%A1%E7%90%86%E4%B8%8E%E8%BF%90%E7%BB%B4"><span class="toc-text">特殊主题的管理与运维</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E4%B8%BB%E9%A2%98%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86"><span class="toc-text">常见主题错误处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%9D%E8%80%83"><span class="toc-text">思考</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E7%BB%84"><span class="toc-text">消费组</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8E%8B%E6%B5%8B"><span class="toc-text">压测</span></a></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By vhicool</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.5</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>