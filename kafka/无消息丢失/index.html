<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Kafka如何保证无消息丢失 | 二九的博客</title><meta name="author" content="vhicool"><meta name="copyright" content="vhicool"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Kafka 只对“已提交”的消息（committed message）做有限度的持久化保证。  已提交 Broker 成功地接收到一条消息并写入到日志文件后，它们会告诉生产者程序这条消息已成功提交。此时，这条消息在 Kafka 看来就正式变为“已提交”消息了。  有限度的持久化保证Kafka 不可能保证在任何情况下都做到不丢失消息。假如你的消息保存在 N 个 Kafka Broker 上，那么这个">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka如何保证无消息丢失">
<meta property="og:url" content="https://vhicool.github.io/kafka/%E6%97%A0%E6%B6%88%E6%81%AF%E4%B8%A2%E5%A4%B1/index.html">
<meta property="og:site_name" content="二九的博客">
<meta property="og:description" content="Kafka 只对“已提交”的消息（committed message）做有限度的持久化保证。  已提交 Broker 成功地接收到一条消息并写入到日志文件后，它们会告诉生产者程序这条消息已成功提交。此时，这条消息在 Kafka 看来就正式变为“已提交”消息了。  有限度的持久化保证Kafka 不可能保证在任何情况下都做到不丢失消息。假如你的消息保存在 N 个 Kafka Broker 上，那么这个">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://vhicool.github.io/img/erjiu.jpeg">
<meta property="article:published_time" content="2025-07-07T14:21:53.000Z">
<meta property="article:modified_time" content="2025-07-13T11:10:33.108Z">
<meta property="article:author" content="vhicool">
<meta property="article:tag" content="java">
<meta property="article:tag" content="kafka">
<meta property="article:tag" content="消息中间件">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://vhicool.github.io/img/erjiu.jpeg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Kafka如何保证无消息丢失",
  "url": "https://vhicool.github.io/kafka/%E6%97%A0%E6%B6%88%E6%81%AF%E4%B8%A2%E5%A4%B1/",
  "image": "https://vhicool.github.io/img/erjiu.jpeg",
  "datePublished": "2025-07-07T14:21:53.000Z",
  "dateModified": "2025-07-13T11:10:33.108Z",
  "author": [
    {
      "@type": "Person",
      "name": "vhicool",
      "url": "https://vhicool.github.io/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://vhicool.github.io/kafka/%E6%97%A0%E6%B6%88%E6%81%AF%E4%B8%A2%E5%A4%B1/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Kafka如何保证无消息丢失',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div class="post" id="body-wrap"><header class="post-bg fixed" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">二九的博客</span></a><a class="nav-page-title" href="/"><span class="site-name">Kafka如何保证无消息丢失</span></a></span><div id="menus"></div></nav><div id="post-info"><h1 class="post-title">Kafka如何保证无消息丢失</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-07-07T14:21:53.000Z" title="发表于 2025-07-07 22:21:53">2025-07-07</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-07-13T11:10:33.108Z" title="更新于 2025-07-13 19:10:33">2025-07-13</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/kafka/">kafka</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><p>Kafka 只对“已提交”的消息（committed message）做有限度的持久化保证。</p>
<ul>
<li><p><strong>已提交</strong></p>
<p>Broker 成功地接收到一条消息并写入到日志文件后，它们会告诉生产者程序这条消息已成功提交。此时，这条消息在 Kafka 看来就正式变为“已提交”消息了。</p>
</li>
<li><p><strong>有限度的持久化保证</strong><br>Kafka 不可能保证在任何情况下都做到不丢失消息。假如你的消息保存在 N 个 Kafka Broker 上，那么这个前提条件就是这 N 个 Broker 中至少有 1 个存活。只要这个条件成立，Kafka 就能保证你的这条消息永远不会丢失。</p>
</li>
</ul>
<h2 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h2><ol>
<li>不要使用 producer.send(msg)，而要使用 producer.send(msg, callback)。记住，一定要使用带有回调通知的 send 方法。</li>
<li>设置 <code>acks = all</code>。acks 是 Producer 的一个参数，代表了你对“已提交”消息的定义。如果设置成 all，则表明所有副本 Broker 都要接收到消息，该消息才算是“已提交”。<strong>这是最高等级的“已提交”定义</strong>。默认值为1<ul>
<li><strong>acks&#x3D;0</strong>：生产者不会等待来自服务器的任何确认。消息被视为发送成功，即使服务器没有收到它。</li>
<li><strong>acks&#x3D;1</strong>：生产者在将消息发送到服务器后会等待服务器的确认。只需要领导者副本（leader replica）确认即可，而不需要等待其他副本的确认（<strong>默认值</strong>）。</li>
<li><strong>acks&#x3D;all</strong>（或者 acks&#x3D;-1）：生产者将等待所有同步副本（包括领导者和所有 ISR 副本）确认。这种设置提供了最高级别的持久性保证。</li>
</ul>
</li>
<li>设置 retries 为一个较大的值。这里的 retries 同样是 Producer 的参数，对应前面提到的 Producer 自动重试。当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了 retries &gt; 0 的 Producer 能够自动重试消息发送，避免消息丢失。</li>
<li>设置 <code>unclean.leader.election.enable = false</code>。这是 Broker 端的参数，它控制的是哪些 Broker 有资格竞选分区的 Leader。如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的 Leader，必然会造成消息的丢失。故一般都要将该参数设置成 false，即不允许这种情况的发生。</li>
<li>设置 <code>replication.factor &gt;= 3</code>。这也是 Broker 端的参数。其实这里想表述的是，最好将消息多保存几份，毕竟目前防止消息丢失的主要机制就是冗余。</li>
<li>设置<code> min.insync.replicas &gt; 1</code>。这依然是 Broker 端参数，控制的是消息至少要被写入到多少个副本才算是“已提交”。设置成大于 1 可以提升消息持久性。在实际环境中千万不要使用默认值 1（<strong>min.insync.replicas只有在acks&#x3D;-1</strong>）。</li>
<li>确保<code>replication.factor &gt; min.insync.replicas</code>。如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了。我们不仅要改善消息的持久性，防止数据丢失，还要在不降低可用性的基础上完成。推荐设置成 <code>replication.factor = min.insync.replicas + 1</code>。</li>
<li>确保消息消费完成再提交。Consumer 端有个参数 enable.auto.commit，最好把它设置成 false，并采用手动提交位移的方式。就像前面说的，这对于单 Consumer 多线程处理的场景而言是至关重要的。</li>
</ol>
<p><strong>acks与min.insync.replicas</strong></p>
<p>当Producer将 acks 设置为“all”（或“-1”）时，<code>min.insync.replicas</code> 指定必须确认写入的最小副本数，写入才会被视为成功。如果无法满足此最小值，则创建者将引发异常（NotEnoughReplicas 或 NotEnoughReplicasAfterAppend）。<br>一起使用时，<code>min.insync.replicas</code> 和 <code>acks</code> 允许您强制执行更高的持久性保证。典型的方案是创建一个复制因子为 3 的主题，将 min.insync.replicas 设置为 2，并使用 “all” 的 acks 进行生成。这将确保在大多数副本未收到写入时，生产者会引发异常。</p>
<p><strong>acks与min.insync.replicas、ISR联系</strong></p>
<ul>
<li>如果设置了<code>acks=all</code>，那么生产者会等待所有ISR中的副本确认消息被写入。</li>
<li><code>min.insync.replicas</code>参数确定了需要有多少个ISR中的副本必须成功写入消息。假如ISR中的副本数少于<code>min.insync.replicas</code>，生产者会接收到一个异常，并且消息不会被认为已成功发送。</li>
<li>通过调整<code>min.insync.replicas</code>和<code>acks</code>，可以在性能和可靠性之间找到平衡。较高的<code>min.insync.replicas</code>值和<code>acks=all</code>设置可以保证更高的数据可靠性，但也会影响写入性能。</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://vhicool.github.io">vhicool</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://vhicool.github.io/kafka/%E6%97%A0%E6%B6%88%E6%81%AF%E4%B8%A2%E5%A4%B1/">https://vhicool.github.io/kafka/%E6%97%A0%E6%B6%88%E6%81%AF%E4%B8%A2%E5%A4%B1/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://vhicool.github.io" target="_blank">二九的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/java/">java</a><a class="post-meta__tags" href="/tags/kafka/">kafka</a><a class="post-meta__tags" href="/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/">消息中间件</a></div><div class="post-share"><div class="social-share" data-image="/img/erjiu.jpeg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/kafka/%E4%BD%8D%E7%82%B9%E4%B8%BB%E9%A2%98-_consumer_offsets/" title="Kafka位点主题：_consumer_offsets是什么"><img class="cover" src="https://vhicool.github.io/kafka/%E4%BD%8D%E7%82%B9%E4%B8%BB%E9%A2%98-_consumer_offsets/86a44073aa60ac33e0833e6a9bfd9ae7.jpeg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">Kafka位点主题：_consumer_offsets是什么</div></div><div class="info-2"><div class="info-item-1">和创建的其他主题一样，位移主题就是普通的 Kafka 主题 位移主题中的消息本质为KV结构，  key保存了3部分内容：group ID、主题名、分区号。 value保存格式有3种 位移值 用于保存 Consumer Group 信息：用来注册 Consumer Group 删除 Group 过期位移甚至是删除 Group 的消息：tombstone 消息，即墓碑消息，也称 delete mark。一旦某个 Consumer Group 下的所有 Consumer 实例都停止了，而且它们的位移数据都已被删除时，Kafka 会向位移主题的对应分区写入 tombstone 消息，表明要彻底删除这个 Group 的信息。    位移主题创建时机当 Kafka 集群中的第一个 Consumer 程序启动时，Kafka 会自动创建位移主题。 分区数：如果是 Kafka 自动创建的，按照Broker 端参数 offsets.topic.num.partitions 的取值，它的默认值是 50。 副本数： Broker 端另一个参数...</div></div></div></a><a class="pagination-related" href="/kafka/kafka%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96/" title="Kafka如何完成数据持久化"><img class="cover" src="https://vhicool.github.io/kafka/kafka%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96/image-20231219234738266.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">Kafka如何完成数据持久化</div></div><div class="info-2"><div class="info-item-1">一、概念Data目录存储二进制消息数据 配置项： 1log.dirs=/Users/vhicool/app-template/kafka-2broker/kafka/broker1  kafka日志末尾附加记录，并且每个日志也被分割成segment。segment有助于删除旧记录，提高性能等等。因此，日志是由segment文件组成的记录的逻辑序列。 Kafka 主题被拆分为多个partition，记录将追加到这些partition。每个分区都可以定义为一个工作单元，而不是存储单元，因为它被客户端用来交换记录。分区进一步拆分为多个segment，这些segment是磁盘上的实际文件。拆分为多个segment确实有助于提高性能（当磁盘上的记录被删除或使用者开始从特定偏移量使用时，大型、未分段的文件速度较慢且更容易出错）。查看broker磁盘，每个主题分区都是一个目录，其中包含相应的 segment 文件和其他文件。以...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/kafka/kafka%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96/" title="Kafka如何完成数据持久化"><img class="cover" src="https://vhicool.github.io/kafka/kafka%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96/image-20231219234738266.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-13</div><div class="info-item-2">Kafka如何完成数据持久化</div></div><div class="info-2"><div class="info-item-1">一、概念Data目录存储二进制消息数据 配置项： 1log.dirs=/Users/vhicool/app-template/kafka-2broker/kafka/broker1  kafka日志末尾附加记录，并且每个日志也被分割成segment。segment有助于删除旧记录，提高性能等等。因此，日志是由segment文件组成的记录的逻辑序列。 Kafka 主题被拆分为多个partition，记录将追加到这些partition。每个分区都可以定义为一个工作单元，而不是存储单元，因为它被客户端用来交换记录。分区进一步拆分为多个segment，这些segment是磁盘上的实际文件。拆分为多个segment确实有助于提高性能（当磁盘上的记录被删除或使用者开始从特定偏移量使用时，大型、未分段的文件速度较慢且更容易出错）。查看broker磁盘，每个主题分区都是一个目录，其中包含相应的 segment 文件和其他文件。以...</div></div></div></a><a class="pagination-related" href="/kafka/kafka%E8%B0%83%E4%BC%98/" title="kafka性能调优"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-07</div><div class="info-item-2">kafka性能调优</div></div><div class="info-2"><div class="info-item-1">操作系统调优 挂载（Mount）文件系统时禁掉 atime 更新 atime 的全称是 access time，记录的是文件最后被访问的时间。记录 atime 需要操作系统访问 inode 资源，而禁掉 atime 可以避免 inode 访问时间的写入操作，减少文件系统的写操作数。你可以执行 mount -o noatime 命令进行设置。  文件系统选择  至少选择ext4 或 XFS，尤其是 XFS 文件系统，它具有高性能、高伸缩性等特点，特别适用于生产服务器。  ZFS 多级缓存的机制能够帮助 Kafka 改善 I&#x2F;O 性能    swap 空间的设置 建议将swappiness 设置成一个很小的值，比如 1～10 之间，以防止 Linux 的 OOM Killer 开启随意杀掉进程 临时设置：sudo sysctl vm.swappiness&#x3D;N 永久设置：修改 &#x2F;etc&#x2F;sysctl.conf 文件，增加 vm.swappiness&#x3D;N，然后重启机器  ulimit -n 如果设置得太小，你会碰到 Too Many...</div></div></div></a><a class="pagination-related" href="/kafka/%E6%B6%88%E8%B4%B9%E7%BB%84%E6%8F%90%E4%BA%A4%E4%BD%8D%E7%A7%BB/" title="Kafka消费组如何提交位移"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-13</div><div class="info-item-2">Kafka消费组如何提交位移</div></div><div class="info-2"><div class="info-item-1">Consumer 需要向 Kafka 汇报自己的位移数据，这个汇报过程被称为提交位移（Committing Offsets）。Consumer 需要为分配给它的每个分区提交各自的位移数据。 一、位移提交方式从用户的角度来说，位移提交分为自动提交和手动提交；从 Consumer 端的角度来说，位移提交分为同步提交和异步提交。 1. 位移提交控制enable.auto.commit：Consumer 端位移提交配置，默认值true，自动提交位移。 auto.commit.interval.ms：它的默认值是 5 秒，表明 Kafka 每 5 秒会为你自动提交一次位移 2. 自动提交位移Kafka 会保证在开始调用 poll 方法时，提交上次 poll 返回的所有消息。从顺序上来说，poll 方法的逻辑是先提交上一批消息的位移，再处理下一批消息，因此它能保证不出现消费丢失的情况。但自动提交位移的一个问题在于，它可能会出现重复消费 1234567891011121314Properties props = new Properties();    ...</div></div></div></a><a class="pagination-related" href="/kafka/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/" title="Kafka常用命令，日常运维必备"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-07</div><div class="info-item-2">Kafka常用命令，日常运维必备</div></div><div class="info-2"><div class="info-item-1">主题 创建主题  –zookeeper 会绕过 Kafka 的安全体系。这就是说，即使你为 Kafka 集群设置了安全认证，限制了主题的创建，如果你使用 –zookeeper 的命令，依然能成功创建任意主题，不受认证体系的约束  1bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 2 --topic test   直接使用–bootstrap-server 与集群进行交互  1bin/kafka-topics.sh --bootstrap-server broker_host:port --create --topic my_topic_name  --partitions 1 --replication-factor 1  发送消息 1bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test  查询指定topic 1bin/kafka-topics.sh...</div></div></div></a><a class="pagination-related" href="/kafka/%E6%B6%88%E8%B4%B9%E7%BB%84rebalance%E8%BF%87%E7%A8%8B/" title="Kafka消费组如何进行重平衡"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-13</div><div class="info-item-2">Kafka消费组如何进行重平衡</div></div><div class="info-2"><div class="info-item-1">一、概念Rebalance 就是让一个 Consumer Group 下所有的 Consumer 实例就如何消费订阅主题的所有分区达成共识的过程。在 Rebalance 过程中，所有 Consumer 实例共同参与，在协调者组件的帮助下，完成订阅主题分区的分配。在整个过程中，所有实例都不能消费任何消息，因此它对 Consumer 的 TPS 影响很大。 Coordinator 它专门为 Consumer Group 服务，负责为 Group 执行 Rebalance 以及提供位移管理和组成员管理等。Consumer 端应用程序在提交位移时，其实是向 Coordinator 所在的 Broker 提交位移。同样地，当 Consumer 应用启动时，也是向 Coordinator 所在的 Broker 发送各种请求，然后由 Coordinator 负责执行消费者组的注册、成员管理记录等元数据管理操作。 所有 Broker 都有各自的 Coordinator 组件，从broker上找到当前分组的协调器， 你可以理解为找到位移主题所在的broker...</div></div></div></a><a class="pagination-related" href="/kafka/%E4%BD%8D%E7%82%B9%E4%B8%BB%E9%A2%98-_consumer_offsets/" title="Kafka位点主题：_consumer_offsets是什么"><img class="cover" src="https://vhicool.github.io/kafka/%E4%BD%8D%E7%82%B9%E4%B8%BB%E9%A2%98-_consumer_offsets/86a44073aa60ac33e0833e6a9bfd9ae7.jpeg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-07</div><div class="info-item-2">Kafka位点主题：_consumer_offsets是什么</div></div><div class="info-2"><div class="info-item-1">和创建的其他主题一样，位移主题就是普通的 Kafka 主题 位移主题中的消息本质为KV结构，  key保存了3部分内容：group ID、主题名、分区号。 value保存格式有3种 位移值 用于保存 Consumer Group 信息：用来注册 Consumer Group 删除 Group 过期位移甚至是删除 Group 的消息：tombstone 消息，即墓碑消息，也称 delete mark。一旦某个 Consumer Group 下的所有 Consumer 实例都停止了，而且它们的位移数据都已被删除时，Kafka 会向位移主题的对应分区写入 tombstone 消息，表明要彻底删除这个 Group 的信息。    位移主题创建时机当 Kafka 集群中的第一个 Consumer 程序启动时，Kafka 会自动创建位移主题。 分区数：如果是 Kafka 自动创建的，按照Broker 端参数 offsets.topic.num.partitions 的取值，它的默认值是 50。 副本数： Broker 端另一个参数...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5"><span class="toc-text">最佳实践</span></a></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By vhicool</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.5</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>