<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Kafka消费组如何提交位移 | 二九的博客</title><meta name="author" content="vhicool"><meta name="copyright" content="vhicool"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Consumer 需要向 Kafka 汇报自己的位移数据，这个汇报过程被称为提交位移（Committing Offsets）。Consumer 需要为分配给它的每个分区提交各自的位移数据。 一、位移提交方式从用户的角度来说，位移提交分为自动提交和手动提交；从 Consumer 端的角度来说，位移提交分为同步提交和异步提交。 1. 位移提交控制enable.auto.commit：Consumer">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka消费组如何提交位移">
<meta property="og:url" content="https://vhicool.github.io/kafka/%E6%B6%88%E8%B4%B9%E7%BB%84%E6%8F%90%E4%BA%A4%E4%BD%8D%E7%A7%BB/index.html">
<meta property="og:site_name" content="二九的博客">
<meta property="og:description" content="Consumer 需要向 Kafka 汇报自己的位移数据，这个汇报过程被称为提交位移（Committing Offsets）。Consumer 需要为分配给它的每个分区提交各自的位移数据。 一、位移提交方式从用户的角度来说，位移提交分为自动提交和手动提交；从 Consumer 端的角度来说，位移提交分为同步提交和异步提交。 1. 位移提交控制enable.auto.commit：Consumer">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://vhicool.github.io/img/erjiu.jpeg">
<meta property="article:published_time" content="2025-02-13T10:53:33.000Z">
<meta property="article:modified_time" content="2025-07-13T11:28:21.972Z">
<meta property="article:author" content="vhicool">
<meta property="article:tag" content="java">
<meta property="article:tag" content="kafka">
<meta property="article:tag" content="消息中间件">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://vhicool.github.io/img/erjiu.jpeg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Kafka消费组如何提交位移",
  "url": "https://vhicool.github.io/kafka/%E6%B6%88%E8%B4%B9%E7%BB%84%E6%8F%90%E4%BA%A4%E4%BD%8D%E7%A7%BB/",
  "image": "https://vhicool.github.io/img/erjiu.jpeg",
  "datePublished": "2025-02-13T10:53:33.000Z",
  "dateModified": "2025-07-13T11:28:21.972Z",
  "author": [
    {
      "@type": "Person",
      "name": "vhicool",
      "url": "https://vhicool.github.io/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://vhicool.github.io/kafka/%E6%B6%88%E8%B4%B9%E7%BB%84%E6%8F%90%E4%BA%A4%E4%BD%8D%E7%A7%BB/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Kafka消费组如何提交位移',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div class="post" id="body-wrap"><header class="post-bg fixed" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">二九的博客</span></a><a class="nav-page-title" href="/"><span class="site-name">Kafka消费组如何提交位移</span></a></span><div id="menus"></div></nav><div id="post-info"><h1 class="post-title">Kafka消费组如何提交位移</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-02-13T10:53:33.000Z" title="发表于 2025-02-13 18:53:33">2025-02-13</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-07-13T11:28:21.972Z" title="更新于 2025-07-13 19:28:21">2025-07-13</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/kafka/">kafka</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><p>Consumer 需要向 Kafka 汇报自己的位移数据，这个汇报过程被称为提交位移（Committing Offsets）。Consumer 需要为分配给它的每个分区提交各自的位移数据。</p>
<h2 id="一、位移提交方式"><a href="#一、位移提交方式" class="headerlink" title="一、位移提交方式"></a>一、位移提交方式</h2><p>从用户的角度来说，位移提交分为自动提交和手动提交；从 Consumer 端的角度来说，位移提交分为同步提交和异步提交。</p>
<h3 id="1-位移提交控制"><a href="#1-位移提交控制" class="headerlink" title="1. 位移提交控制"></a>1. 位移提交控制</h3><p><code>enable.auto.commit</code>：Consumer 端位移提交配置，默认值true，自动提交位移。</p>
<p><code>auto.commit.interval.ms</code>：它的默认值是 5 秒，表明 Kafka 每 5 秒会为你自动提交一次位移</p>
<h3 id="2-自动提交位移"><a href="#2-自动提交位移" class="headerlink" title="2. 自动提交位移"></a>2. 自动提交位移</h3><p>Kafka 会保证在开始调用 poll 方法时，提交上次 poll 返回的所有消息。从顺序上来说，poll 方法的逻辑是先提交上一批消息的位移，再处理下一批消息，因此它能保证<strong>不出现消费丢失</strong>的情况。但自动提交位移的一个问题在于，它可能会出现重复消费</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Properties</span> <span class="variable">props</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">     props.put(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;localhost:9092&quot;</span>);</span><br><span class="line">     props.put(<span class="string">&quot;group.id&quot;</span>, <span class="string">&quot;test&quot;</span>);</span><br><span class="line">     props.put(<span class="string">&quot;enable.auto.commit&quot;</span>, <span class="string">&quot;true&quot;</span>);</span><br><span class="line">     props.put(<span class="string">&quot;auto.commit.interval.ms&quot;</span>, <span class="string">&quot;2000&quot;</span>);</span><br><span class="line">     props.put(<span class="string">&quot;key.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line">     props.put(<span class="string">&quot;value.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line">KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> <span class="title class_">KafkaConsumer</span>&lt;&gt;(props);</span><br><span class="line">     consumer.subscribe(Arrays.asList(<span class="string">&quot;foo&quot;</span>, <span class="string">&quot;bar&quot;</span>));</span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">100</span>);</span><br><span class="line">         <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records)</span><br><span class="line">        System.out.printf(<span class="string">&quot;offset = %d, key = %s, value = %s%n&quot;</span>, record.offset(), record.key(),record.value());</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>



<h3 id="3-手动提交位移"><a href="#3-手动提交位移" class="headerlink" title="3. 手动提交位移"></a>3. 手动提交位移</h3><ul>
<li><p>同步提交</p>
<p>该方法会提交 KafkaConsumer#poll() 返回的最新位移</p>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">ConsumerRecords&lt;String, String&gt; records =</span><br><span class="line">        consumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">process(records); <span class="comment">// 处理消息</span></span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                    consumer.commitSync();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (CommitFailedException e) &#123;</span><br><span class="line">handle(e); <span class="comment">// 处理提交失败异常</span></span><br><span class="line">            &#125;</span><br><span class="line">                    &#125;</span><br></pre></td></tr></table></figure>



<ul>
<li><p>异步提交</p>
<p>调用 commitAsync() 之后，它会立即返回，不会阻塞，因此不会影响 Consumer 应用的 TPS，commitAsync 是不会自动重试的。</p>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">ConsumerRecords&lt;String, String&gt; records =</span><br><span class="line">        consumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">process(records); <span class="comment">// 处理消息</span></span><br><span class="line">            consumer.commitAsync((offsets, exception) -&gt; &#123;</span><br><span class="line">        <span class="keyword">if</span> (exception != <span class="literal">null</span>)</span><br><span class="line">handle(exception);</span><br><span class="line">  &#125;);</span><br><span class="line">          &#125;</span><br></pre></td></tr></table></figure>



<ul>
<li><p>同步异步结合</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">           <span class="keyword">while</span>(<span class="literal">true</span>) &#123;</span><br><span class="line">                        ConsumerRecords&lt;String, String&gt; records = </span><br><span class="line">                                    consumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">                        process(records); <span class="comment">// 处理消息</span></span><br><span class="line">                        commitAysnc(); <span class="comment">// 使用异步提交规避阻塞</span></span><br><span class="line">            &#125;</span><br><span class="line">&#125; <span class="keyword">catch</span>(Exception e) &#123;</span><br><span class="line">    handle(e); <span class="comment">// 处理异常</span></span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">   <span class="keyword">try</span> &#123;</span><br><span class="line">         consumer.commitSync(); <span class="comment">// 最后一次提交使用同步阻塞式提交</span></span><br><span class="line">   &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">       consumer.close();</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>批量提交位点</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line"><span class="type">int</span> <span class="variable">count</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">……</span><br><span class="line"><span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">            ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record: records) &#123;</span><br><span class="line">                        process(record);  <span class="comment">// 处理消息</span></span><br><span class="line">                        offsets.put(<span class="keyword">new</span> <span class="title class_">TopicPartition</span>(record.topic(), record.partition()),</span><br><span class="line">                                   <span class="keyword">new</span> <span class="title class_">OffsetAndMetadata</span>(record.offset() + <span class="number">1</span>)；</span><br><span class="line">                       <span class="keyword">if</span>（count % <span class="number">100</span> == <span class="number">0</span>）</span><br><span class="line">                                    consumer.commitAsync(offsets, <span class="literal">null</span>); <span class="comment">// 回调处理逻辑是null</span></span><br><span class="line">                        count++;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<p><strong>Standalone Consumer</strong></p>
<ol>
<li>很多流处理框架的Kafka connector都没有使用consumer group，而是直接使用standalone consumer，因为group机制不好把控</li>
<li>standalone consumer没有rebalance，也没有group提供的负载均衡，你需要自己实现。其他方面（比如位移提交）和group没有太大的不同</li>
</ol>
<h2 id="二、查看消费进度"><a href="#二、查看消费进度" class="headerlink" title="二、查看消费进度"></a>二、查看消费进度</h2><h3 id="1-需要关注消费进度引起的问题"><a href="#1-需要关注消费进度引起的问题" class="headerlink" title="1. 需要关注消费进度引起的问题"></a>1. 需要关注消费进度引起的问题</h3><p>消费速度小于主题发送消息速度，当消费延迟越来越大，导致消费的数据已经不在操作系统的页缓存中，消费组者不得不从磁盘读取它们，这样就进一步拉大延迟</p>
<h3 id="2-消费延迟查看方式"><a href="#2-消费延迟查看方式" class="headerlink" title="2. 消费延迟查看方式"></a>2. 消费延迟查看方式</h3><ol>
<li><p>Kafka 自带的命令行工具 kafka-consumer-groups 脚本</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">bin/kafka-consumer-groups.sh --bootstrap-server &lt;Kafka broker连接信息&gt; --describe --group &lt;group名称&gt;</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="三、常见异常"><a href="#三、常见异常" class="headerlink" title="三、常见异常"></a>三、常见异常</h2><h3 id="CommitFailedException"><a href="#CommitFailedException" class="headerlink" title="CommitFailedException"></a>CommitFailedException</h3><blockquote>
<p>自动commit 不会抛 CommitFailedException</p>
</blockquote>
<ul>
<li><p>原因<br>是消费者组已经开启了 Rebalance 过程，并且将要提交位移的分区分配给了另一个消费者实例。出现这个情况的原因是，你的消费者实例连续两次调用 poll 方法的时间间隔超过了期望的 max.poll.interval.ms 参数值。这通常表明，你的消费者实例花费了太长的时间进行消息处理，耽误了调用 poll 方法。如：Consumer 端参数 <code>max.poll.interval.ms=5</code> 秒，最后在循环调用 KafkaConsumer.poll 方法之间，插入 <code>Thread.sleep(6000)</code> 和手动提交位移，会出现<code>CommitFailedException</code></p>
</li>
<li><p>解决方法</p>
<ol>
<li><p>客户端优化</p>
<ul>
<li>缩短单条消息处理的时间</li>
<li>下游系统使用多线程来加速消费</li>
</ul>
</li>
<li><p>客户端配置</p>
<ul>
<li><p>增加期望的时间间隔 <code>max.poll.interval.ms</code> 参数值。</p>
</li>
<li><p>减少 poll 方法一次性返回的消息数量，即减少 <code>max.poll.records</code> 参数值。</p>
</li>
</ul>
</li>
</ol>
<p><strong>其他导致CommitFailedException异常的情况</strong></p>
<p>设置相同group.id 值的消费者组程序和Standalone Consumer 的独立消费程序，那么当独立消费者程序手动提交位移时，Kafka 就会立即抛出 CommitFailedException 异常</p>
</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://vhicool.github.io">vhicool</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://vhicool.github.io/kafka/%E6%B6%88%E8%B4%B9%E7%BB%84%E6%8F%90%E4%BA%A4%E4%BD%8D%E7%A7%BB/">https://vhicool.github.io/kafka/%E6%B6%88%E8%B4%B9%E7%BB%84%E6%8F%90%E4%BA%A4%E4%BD%8D%E7%A7%BB/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://vhicool.github.io" target="_blank">二九的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/java/">java</a><a class="post-meta__tags" href="/tags/kafka/">kafka</a><a class="post-meta__tags" href="/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/">消息中间件</a></div><div class="post-share"><div class="social-share" data-image="/img/erjiu.jpeg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/kafka/%E4%BD%8D%E7%82%B9%E4%B8%BB%E9%A2%98-_consumer_offsets/" title="Kafka位点主题：_consumer_offsets是什么"><img class="cover" src="https://vhicool.github.io/kafka/%E4%BD%8D%E7%82%B9%E4%B8%BB%E9%A2%98-_consumer_offsets/86a44073aa60ac33e0833e6a9bfd9ae7.jpeg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">Kafka位点主题：_consumer_offsets是什么</div></div><div class="info-2"><div class="info-item-1">和创建的其他主题一样，位移主题就是普通的 Kafka 主题 位移主题中的消息本质为KV结构，  key保存了3部分内容：group ID、主题名、分区号。 value保存格式有3种 位移值 用于保存 Consumer Group 信息：用来注册 Consumer Group 删除 Group 过期位移甚至是删除 Group 的消息：tombstone 消息，即墓碑消息，也称 delete mark。一旦某个 Consumer Group 下的所有 Consumer 实例都停止了，而且它们的位移数据都已被删除时，Kafka 会向位移主题的对应分区写入 tombstone 消息，表明要彻底删除这个 Group 的信息。    位移主题创建时机当 Kafka 集群中的第一个 Consumer 程序启动时，Kafka 会自动创建位移主题。 分区数：如果是 Kafka 自动创建的，按照Broker 端参数 offsets.topic.num.partitions 的取值，它的默认值是 50。 副本数： Broker 端另一个参数...</div></div></div></a><a class="pagination-related" href="/kafka/%E6%B6%88%E8%B4%B9%E7%BB%84rebalance%E8%BF%87%E7%A8%8B/" title="Kafka消费组如何进行重平衡"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">Kafka消费组如何进行重平衡</div></div><div class="info-2"><div class="info-item-1">一、概念Rebalance 就是让一个 Consumer Group 下所有的 Consumer 实例就如何消费订阅主题的所有分区达成共识的过程。在 Rebalance 过程中，所有 Consumer 实例共同参与，在协调者组件的帮助下，完成订阅主题分区的分配。在整个过程中，所有实例都不能消费任何消息，因此它对 Consumer 的 TPS 影响很大。 Coordinator 它专门为 Consumer Group 服务，负责为 Group 执行 Rebalance 以及提供位移管理和组成员管理等。Consumer 端应用程序在提交位移时，其实是向 Coordinator 所在的 Broker 提交位移。同样地，当 Consumer 应用启动时，也是向 Coordinator 所在的 Broker 发送各种请求，然后由 Coordinator 负责执行消费者组的注册、成员管理记录等元数据管理操作。 所有 Broker 都有各自的 Coordinator 组件，从broker上找到当前分组的协调器， 你可以理解为找到位移主题所在的broker...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/kafka/kafka%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96/" title="Kafka如何完成数据持久化"><img class="cover" src="https://vhicool.github.io/kafka/kafka%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96/image-20231219234738266.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-03</div><div class="info-item-2">Kafka如何完成数据持久化</div></div><div class="info-2"><div class="info-item-1">一、概念Data目录存储二进制消息数据 配置项： 1log.dirs=/Users/vhicool/app-template/kafka-2broker/kafka/broker1  kafka日志末尾附加记录，并且每个日志也被分割成segment。segment有助于删除旧记录，提高性能等等。因此，日志是由segment文件组成的记录的逻辑序列。 Kafka 主题被拆分为多个partition，记录将追加到这些partition。每个分区都可以定义为一个工作单元，而不是存储单元，因为它被客户端用来交换记录。分区进一步拆分为多个segment，这些segment是磁盘上的实际文件。拆分为多个segment确实有助于提高性能（当磁盘上的记录被删除或使用者开始从特定偏移量使用时，大型、未分段的文件速度较慢且更容易出错）。查看broker磁盘，每个主题分区都是一个目录，其中包含相应的 segment 文件和其他文件。以...</div></div></div></a><a class="pagination-related" href="/kafka/kafka%E8%B0%83%E4%BC%98/" title="kafka性能调优"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-17</div><div class="info-item-2">kafka性能调优</div></div><div class="info-2"><div class="info-item-1">操作系统调优 挂载（Mount）文件系统时禁掉 atime 更新 atime 的全称是 access time，记录的是文件最后被访问的时间。记录 atime 需要操作系统访问 inode 资源，而禁掉 atime 可以避免 inode 访问时间的写入操作，减少文件系统的写操作数。你可以执行 mount -o noatime 命令进行设置。  文件系统选择  至少选择ext4 或 XFS，尤其是 XFS 文件系统，它具有高性能、高伸缩性等特点，特别适用于生产服务器。  ZFS 多级缓存的机制能够帮助 Kafka 改善 I&#x2F;O 性能    swap 空间的设置 建议将swappiness 设置成一个很小的值，比如 1～10 之间，以防止 Linux 的 OOM Killer 开启随意杀掉进程 临时设置：sudo sysctl vm.swappiness&#x3D;N 永久设置：修改 &#x2F;etc&#x2F;sysctl.conf 文件，增加 vm.swappiness&#x3D;N，然后重启机器  ulimit -n 如果设置得太小，你会碰到 Too Many...</div></div></div></a><a class="pagination-related" href="/kafka/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/" title="Kafka常用命令，日常运维必备"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-01-07</div><div class="info-item-2">Kafka常用命令，日常运维必备</div></div><div class="info-2"><div class="info-item-1">主题 创建主题  –zookeeper 会绕过 Kafka 的安全体系。这就是说，即使你为 Kafka 集群设置了安全认证，限制了主题的创建，如果你使用 –zookeeper 的命令，依然能成功创建任意主题，不受认证体系的约束  1bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 2 --topic test   直接使用–bootstrap-server 与集群进行交互  1bin/kafka-topics.sh --bootstrap-server broker_host:port --create --topic my_topic_name  --partitions 1 --replication-factor 1  发送消息 1bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test  查询指定topic 1bin/kafka-topics.sh...</div></div></div></a><a class="pagination-related" href="/kafka/%E6%97%A0%E6%B6%88%E6%81%AF%E4%B8%A2%E5%A4%B1/" title="Kafka如何保证无消息丢失"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-01-27</div><div class="info-item-2">Kafka如何保证无消息丢失</div></div><div class="info-2"><div class="info-item-1">Kafka 只对“已提交”的消息（committed message）做有限度的持久化保证。  已提交 Broker 成功地接收到一条消息并写入到日志文件后，它们会告诉生产者程序这条消息已成功提交。此时，这条消息在 Kafka 看来就正式变为“已提交”消息了。  有限度的持久化保证Kafka 不可能保证在任何情况下都做到不丢失消息。假如你的消息保存在 N 个 Kafka Broker 上，那么这个前提条件就是这 N 个 Broker 中至少有 1 个存活。只要这个条件成立，Kafka 就能保证你的这条消息永远不会丢失。   最佳实践 不要使用 producer.send(msg)，而要使用 producer.send(msg, callback)。记住，一定要使用带有回调通知的 send 方法。 设置 acks = all。acks 是 Producer 的一个参数，代表了你对“已提交”消息的定义。如果设置成 all，则表明所有副本 Broker...</div></div></div></a><a class="pagination-related" href="/kafka/%E6%B6%88%E8%B4%B9%E7%BB%84rebalance%E8%BF%87%E7%A8%8B/" title="Kafka消费组如何进行重平衡"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-02-23</div><div class="info-item-2">Kafka消费组如何进行重平衡</div></div><div class="info-2"><div class="info-item-1">一、概念Rebalance 就是让一个 Consumer Group 下所有的 Consumer 实例就如何消费订阅主题的所有分区达成共识的过程。在 Rebalance 过程中，所有 Consumer 实例共同参与，在协调者组件的帮助下，完成订阅主题分区的分配。在整个过程中，所有实例都不能消费任何消息，因此它对 Consumer 的 TPS 影响很大。 Coordinator 它专门为 Consumer Group 服务，负责为 Group 执行 Rebalance 以及提供位移管理和组成员管理等。Consumer 端应用程序在提交位移时，其实是向 Coordinator 所在的 Broker 提交位移。同样地，当 Consumer 应用启动时，也是向 Coordinator 所在的 Broker 发送各种请求，然后由 Coordinator 负责执行消费者组的注册、成员管理记录等元数据管理操作。 所有 Broker 都有各自的 Coordinator 组件，从broker上找到当前分组的协调器， 你可以理解为找到位移主题所在的broker...</div></div></div></a><a class="pagination-related" href="/kafka/%E4%BD%8D%E7%82%B9%E4%B8%BB%E9%A2%98-_consumer_offsets/" title="Kafka位点主题：_consumer_offsets是什么"><img class="cover" src="https://vhicool.github.io/kafka/%E4%BD%8D%E7%82%B9%E4%B8%BB%E9%A2%98-_consumer_offsets/86a44073aa60ac33e0833e6a9bfd9ae7.jpeg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-02-07</div><div class="info-item-2">Kafka位点主题：_consumer_offsets是什么</div></div><div class="info-2"><div class="info-item-1">和创建的其他主题一样，位移主题就是普通的 Kafka 主题 位移主题中的消息本质为KV结构，  key保存了3部分内容：group ID、主题名、分区号。 value保存格式有3种 位移值 用于保存 Consumer Group 信息：用来注册 Consumer Group 删除 Group 过期位移甚至是删除 Group 的消息：tombstone 消息，即墓碑消息，也称 delete mark。一旦某个 Consumer Group 下的所有 Consumer 实例都停止了，而且它们的位移数据都已被删除时，Kafka 会向位移主题的对应分区写入 tombstone 消息，表明要彻底删除这个 Group 的信息。    位移主题创建时机当 Kafka 集群中的第一个 Consumer 程序启动时，Kafka 会自动创建位移主题。 分区数：如果是 Kafka 自动创建的，按照Broker 端参数 offsets.topic.num.partitions 的取值，它的默认值是 50。 副本数： Broker 端另一个参数...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E4%BD%8D%E7%A7%BB%E6%8F%90%E4%BA%A4%E6%96%B9%E5%BC%8F"><span class="toc-text">一、位移提交方式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E4%BD%8D%E7%A7%BB%E6%8F%90%E4%BA%A4%E6%8E%A7%E5%88%B6"><span class="toc-text">1. 位移提交控制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E8%87%AA%E5%8A%A8%E6%8F%90%E4%BA%A4%E4%BD%8D%E7%A7%BB"><span class="toc-text">2. 自动提交位移</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E6%89%8B%E5%8A%A8%E6%8F%90%E4%BA%A4%E4%BD%8D%E7%A7%BB"><span class="toc-text">3. 手动提交位移</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E6%9F%A5%E7%9C%8B%E6%B6%88%E8%B4%B9%E8%BF%9B%E5%BA%A6"><span class="toc-text">二、查看消费进度</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E9%9C%80%E8%A6%81%E5%85%B3%E6%B3%A8%E6%B6%88%E8%B4%B9%E8%BF%9B%E5%BA%A6%E5%BC%95%E8%B5%B7%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-text">1. 需要关注消费进度引起的问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%B6%88%E8%B4%B9%E5%BB%B6%E8%BF%9F%E6%9F%A5%E7%9C%8B%E6%96%B9%E5%BC%8F"><span class="toc-text">2. 消费延迟查看方式</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E5%B8%B8%E8%A7%81%E5%BC%82%E5%B8%B8"><span class="toc-text">三、常见异常</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#CommitFailedException"><span class="toc-text">CommitFailedException</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By vhicool</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.5</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>